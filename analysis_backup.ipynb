{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4caf37cc",
   "metadata": {},
   "source": [
    "# Import y definiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf37c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Análisis de tracking extendido:\n",
    "- Agregación por secuencia, modelo, formato y promedios.\n",
    "- Detección flexible de columnas de métricas y curvas IoU.\n",
    "- Normalización y composite_score con pesos configurables.\n",
    "- Gráficas de barras para métricas clave, IDSW/Frag, curvas IoU y heatmaps.\n",
    "- Comparaciones entre formatos (solo FACTOR DE MEJORA = Métrica_target / Métrica_baseline).\n",
    "- Gráficas de factor de mejora como CURVAS (no barras) por modelo y por secuencia.\n",
    "- Gráficas opcionales para combinaciones específicas (modelo + formato).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "# =========================================================\n",
    "# CONFIGURACIÓN\n",
    "# =========================================================\n",
    "IN_PATH: str = \"combined_results.csv\"\n",
    "OUT_DIR: str = \"results\"\n",
    "SEQ_LIST: list[str] = [\"Tracking1\", \"Tracking2\"]\n",
    "DESIRED_ORDER_MODELS: list[str] = ['Salmones2024','yolov8m','yolov8l','yolov9c','yolo11m','yolo11l']\n",
    "DESIRED_ORDER_FORMATS: list[str] = [\"Pytorch\", \"FP16\", \"INT8\"]\n",
    "\n",
    "COMPOSITE_WEIGHTS: dict[str, float] = {\n",
    "    'AssA_AUC_norm': 0.35,\n",
    "    'IDF1_norm': 0.25,\n",
    "    'HOTA_AUC_norm': 0.15,\n",
    "    'MT_percent_norm': 0.10,\n",
    "    'IDSW_norm': -0.10,\n",
    "    'Frag_norm': -0.10\n",
    "}\n",
    "\n",
    "METRIC_PATTERNS = [\n",
    "    ('AssA_AUC', ['AssA___AUC','AssA_AUC','AssA AUC','AssA']),\n",
    "    ('IDF1',     ['IDF1','IDF_1','ID_F1']),\n",
    "    ('HOTA_AUC', ['HOTA___AUC','HOTA_AUC','HOTA']),\n",
    "    ('MT',       ['MT','MTR','Mostly-Tracked','MostlyTracked']),\n",
    "    ('GT_IDs',   ['GT_IDs','GT_IDS','GT_ID','GT_IDs','GT_ID']),\n",
    "    ('IDSW',     ['IDSW','ID Sw','ID_Switches','id switches']),\n",
    "    ('Frag',     ['Frag','Fragmentation','FRAG']),\n",
    "    ('Dets',     ['Dets','Detections','GT_Dets','Dets ']),\n",
    "]\n",
    "\n",
    "ASSA_PREFIX = \"AssA___\"\n",
    "DETA_PREFIX = \"DetA___\"\n",
    "\n",
    "# =========================================================\n",
    "# COMPARACIONES (SOLO FACTOR DE MEJORA)\n",
    "# =========================================================\n",
    "BASELINE_FORMAT: str = \"Pytorch\"\n",
    "COMPARISON_TARGET_FORMATS: list[str] = [\"FP16\", \"INT8\"]\n",
    "COMPARISON_METRICS_CANDIDATES = ['AssA_AUC','IDF1','HOTA_AUC','MT_percent','IDSW','Frag']\n",
    "ALLOWED_EXPORT_METRICS = ['IDF1','AssA_AUC','HOTA_AUC','Det_AUC','MT_percent','IDSW','Frag']\n",
    "\n",
    "\n",
    "# Combinaciones específicas (modelo, formato) para graficar métricas por secuencia\n",
    "SPECIFIC_MODEL_FORMATS: list[tuple[str, str]] = [\n",
    "    # ('yolov8m','FP16'),\n",
    "    # ('yolov8m','INT8'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4686a5c",
   "metadata": {},
   "source": [
    "# Utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0411478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# UTILIDADES\n",
    "# =========================================================\n",
    "def log(msg: str):\n",
    "    print(msg)\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def choose_col(df: pd.DataFrame, patterns: list[str]) -> str | None:\n",
    "    for p in patterns:\n",
    "        if p in df.columns:\n",
    "            return p\n",
    "    for p in patterns:\n",
    "        matches = [c for c in df.columns if p.lower() in c.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    return None\n",
    "\n",
    "def reorder_index(df_in: pd.DataFrame, order: list[str]) -> pd.DataFrame:\n",
    "    if df_in.empty or not order:\n",
    "        return df_in\n",
    "    present = [m for m in order if m in df_in.index]\n",
    "    others = [m for m in df_in.index if m not in present]\n",
    "    return df_in.reindex(present + others)\n",
    "\n",
    "def to_numeric_safe(df: pd.DataFrame, cols: list[str]):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "def minmax_cols(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    keep = [c for c in cols if c in d.columns]\n",
    "    if not keep:\n",
    "        return d\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(d[keep])\n",
    "    for i, c in enumerate(keep):\n",
    "        d[c + \"_norm\"] = scaled[:, i]\n",
    "    return d\n",
    "\n",
    "def compute_composite(df_in: pd.DataFrame, weights: dict[str,float]) -> pd.DataFrame:\n",
    "    df = df_in.copy()\n",
    "    if df.empty:\n",
    "        return df\n",
    "    usable_weights = {k:v for k,v in weights.items() if k in df.columns}\n",
    "    if not usable_weights:\n",
    "        df['composite_score_raw'] = 0.0\n",
    "        df['composite_score'] = 0.0\n",
    "        return df\n",
    "    raw = pd.Series(0.0, index=df.index, dtype=float)\n",
    "    for k, w in usable_weights.items():\n",
    "        raw += w * df[k]\n",
    "    df['composite_score_raw'] = raw\n",
    "    if raw.max() > raw.min():\n",
    "        df['composite_score'] = (raw - raw.min())/(raw.max()-raw.min())\n",
    "    else:\n",
    "        df['composite_score'] = 0.0\n",
    "    return df\n",
    "\n",
    "def safe_vals(df_g: pd.DataFrame, metric: str, ordered: list[str]) -> list[float]:\n",
    "    def to_real(val):\n",
    "        if pd.isna(val): return float('nan')\n",
    "        if isinstance(val, complex): return float('nan')\n",
    "        try: return float(val)\n",
    "        except: return float('nan')\n",
    "    return [to_real(df_g.loc[m, metric]) if (m in df_g.index and metric in df_g.columns) else float('nan') for m in ordered]\n",
    "\n",
    "def detect_metric_columns(df: pd.DataFrame) -> dict[str,str]:\n",
    "    mapping = {}\n",
    "    for short, patterns in METRIC_PATTERNS:\n",
    "        col = choose_col(df, patterns)\n",
    "        if col:\n",
    "            mapping[short] = col\n",
    "    return mapping\n",
    "\n",
    "def build_agg_map(df: pd.DataFrame, metrics_map: dict[str,str]) -> dict[str,str]:\n",
    "    cols = [v for v in metrics_map.values() if v in df.columns and pd.api.types.is_numeric_dtype(df[v])]\n",
    "    return {c: 'mean' for c in cols}\n",
    "\n",
    "def add_mt_percent(df: pd.DataFrame, metrics_map: dict[str,str]) -> None:\n",
    "    mt_col = metrics_map.get('MT')\n",
    "    gt_col = metrics_map.get('GT_IDs')\n",
    "    if mt_col and gt_col and mt_col in df.columns and gt_col in df.columns:\n",
    "        df[mt_col] = pd.to_numeric(df[mt_col], errors='coerce')\n",
    "        df[gt_col] = pd.to_numeric(df[gt_col], errors='coerce')\n",
    "        df['MT_percent'] = df[mt_col] / df[gt_col].replace({0: np.nan})\n",
    "    else:\n",
    "        df['MT_percent'] = np.nan\n",
    "\n",
    "def group_and_rename(df_sub: pd.DataFrame, group_col: str, agg_map: dict[str,str], metrics_map: dict[str,str]) -> pd.DataFrame:\n",
    "    if df_sub.empty:\n",
    "        return pd.DataFrame()\n",
    "    usable = {k:v for k,v in agg_map.items() if k in df_sub.columns}\n",
    "    if not usable:\n",
    "        return pd.DataFrame()\n",
    "    g = df_sub.groupby(group_col).agg(usable)\n",
    "    rename_map = {v:k for k,v in metrics_map.items() if v in g.columns}\n",
    "    g = g.rename(columns=rename_map)\n",
    "    if 'MT_percent' in df_sub.columns:\n",
    "        g['MT_percent'] = df_sub.groupby(group_col)['MT_percent'].mean()\n",
    "    return g\n",
    "\n",
    "def normalize_and_composite(df_metrics: pd.DataFrame, weights: dict[str,float]) -> pd.DataFrame:\n",
    "    if df_metrics.empty:\n",
    "        return df_metrics\n",
    "    base = df_metrics.copy().fillna(0)\n",
    "    norm_candidates = ['AssA_AUC','IDF1','HOTA_AUC','MT_percent','IDSW','Frag']\n",
    "    base = minmax_cols(base, [c for c in norm_candidates if c in base.columns])\n",
    "    return compute_composite(base, weights)\n",
    "\n",
    "def compute_average(grouped_per_seq: dict[str,pd.DataFrame]) -> pd.DataFrame:\n",
    "    seq_dfs = [df for name, df in grouped_per_seq.items() if name in SEQ_LIST and not df.empty]\n",
    "    if not seq_dfs:\n",
    "        return pd.DataFrame()\n",
    "    common_cols = set(seq_dfs[0].columns)\n",
    "    for d in seq_dfs[1:]:\n",
    "        common_cols &= set(d.columns)\n",
    "    common_cols = [c for c in common_cols if pd.api.types.is_numeric_dtype(seq_dfs[0][c])]\n",
    "    if not common_cols:\n",
    "        return pd.DataFrame()\n",
    "    all_index = sorted(set().union(*[d.index for d in seq_dfs]))\n",
    "    stacked = [d.reindex(all_index) for d in seq_dfs]\n",
    "    concat = pd.concat(stacked, keys=range(len(seq_dfs)))\n",
    "    return concat.groupby(level=1)[common_cols].mean()\n",
    "\n",
    "def plot_group_bars(group_df: pd.DataFrame, name: str, group_type: str, ordered: list[str], metrics: list[str], out_dir: str, figsize=(7,4)):\n",
    "    if group_df.empty:\n",
    "        return\n",
    "    x_labels = ordered if ordered else list(group_df.index)\n",
    "    x = np.arange(len(x_labels))\n",
    "    width = 0.15\n",
    "    n = len(metrics)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, metric in enumerate(metrics):\n",
    "        vals = safe_vals(group_df, metric, x_labels)\n",
    "        plt.bar(x + (i-(n-1)/2)*width, vals, width, label=metric)\n",
    "    #plt.xticks(x, x_labels, rotation=45, ha='right')\n",
    "    plt.xticks(x, x_labels)\n",
    "    plt.ylabel(\"Valor medio\")\n",
    "    # plt.title(f\"Métricas clave por {group_type} - {name}\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    path = os.path.join(out_dir, f\"metricas_clave_{group_type}_{name}.pdf\")\n",
    "    plt.savefig(path); plt.close()\n",
    "    log(f\"Plot guardado: {path}\")\n",
    "\n",
    "def plot_idsw_frag(group_df: pd.DataFrame, name: str, group_type: str, ordered: list[str], out_dir: str, figsize=(7,4)):\n",
    "    if group_df.empty:\n",
    "        return\n",
    "    if 'IDSW' not in group_df.columns and 'Frag' not in group_df.columns:\n",
    "        return\n",
    "    x_labels = ordered if ordered else list(group_df.index)\n",
    "    x = np.arange(len(x_labels))\n",
    "    width = 0.35\n",
    "    idsw_vals = safe_vals(group_df, 'IDSW', x_labels)\n",
    "    frag_vals = safe_vals(group_df, 'Frag', x_labels)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.bar(x - width/2, idsw_vals, width, label='IDSW')\n",
    "    plt.bar(x + width/2, frag_vals, width, label='Frag')\n",
    "    #plt.xticks(x, x_labels, rotation=45, ha='right')\n",
    "    plt.xticks(x, x_labels)\n",
    "    plt.ylabel(\"Valor medio\")\n",
    "    # plt.title(f\"IDSW y Frag por {group_type} - {name}\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    path = os.path.join(out_dir, f\"idsw_frag_{group_type}_{name}.pdf\")\n",
    "    plt.savefig(path); plt.close()\n",
    "    log(f\"Plot guardado: {path}\")\n",
    "\n",
    "def plot_curves_by_iou(df: pd.DataFrame, group_col: str, prefix: str, thresholds: list[int], cols: list[str], ordered: list[str], title_metric: str, tag: str, name: str, out_dir: str, figsize=(7,4)):\n",
    "    if not cols or group_col not in df.columns:\n",
    "        return\n",
    "    mean_table = df.groupby(group_col)[cols].mean()\n",
    "    plt.figure(figsize=figsize)\n",
    "    for g in (ordered if ordered else mean_table.index):\n",
    "        if g in mean_table.index:\n",
    "            plt.plot(np.array(thresholds), mean_table.loc[g].to_numpy(), marker='o', label=g)\n",
    "    # plt.xlabel(\"IoU threshold (%)\")\n",
    "    plt.ylabel(title_metric)\n",
    "    plt.title(f\"{title_metric} vs IoU - {name} ({tag})\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    path = os.path.join(out_dir, f\"{prefix.lower()}_vs_iou_{tag}_{name}.pdf\")\n",
    "    plt.savefig(path); plt.close()\n",
    "    log(f\"Plot guardado: {path}\")\n",
    "\n",
    "def heatmap(matrix: pd.DataFrame, title: str, path: str):\n",
    "    if matrix.empty:\n",
    "        log(f\"Heatmap vacío: {path}\")\n",
    "        return\n",
    "    plt.figure(figsize=(8, 2 + 0.6*len(matrix.index)))\n",
    "    plt.imshow(matrix.values, aspect='auto', interpolation='nearest')\n",
    "    plt.yticks(range(len(matrix.index)), matrix.index.tolist())\n",
    "    #plt.xticks(range(len(matrix.columns)), matrix.columns.tolist(), rotation=45, ha='right')\n",
    "    plt.xticks(range(len(matrix.columns)), matrix.columns.tolist())\n",
    "    plt.colorbar(label='composite_score (0-1)')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path); plt.close()\n",
    "    log(f\"Heatmap guardado: {path}\")\n",
    "\n",
    "# =========================================================\n",
    "# COMPARACIONES FACTOR DE MEJORA\n",
    "# =========================================================\n",
    "def aggregate_seq_model_format(df: pd.DataFrame, seq_list: list[str], model_col: str, format_col: str,\n",
    "                               metrics_map: dict[str,str]) -> pd.DataFrame:\n",
    "    if any(col not in df.columns for col in ['seq', model_col, format_col]):\n",
    "        return pd.DataFrame()\n",
    "    subset = df[df['seq'].isin(seq_list)].copy()\n",
    "    numeric_cols = list(metrics_map.values())\n",
    "    if 'MT_percent' in subset.columns:\n",
    "        numeric_cols.append('MT_percent')\n",
    "    numeric_cols = [c for c in numeric_cols if c in subset.columns]\n",
    "    grp = subset.groupby(['seq', model_col, format_col])[numeric_cols].mean().reset_index()\n",
    "    rename_map = {v:k for k,v in metrics_map.items() if v in grp.columns}\n",
    "    grp = grp.rename(columns=rename_map)\n",
    "    return grp\n",
    "\n",
    "def compute_format_factor(df_triplet: pd.DataFrame,\n",
    "                          model_col: str,\n",
    "                          format_col: str,\n",
    "                          baseline_format: str,\n",
    "                          target_formats: list[str],\n",
    "                          metrics: list[str]) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Factor de mejora = valor_target / valor_baseline\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    if df_triplet.empty:\n",
    "        return results\n",
    "    metrics = [m for m in metrics if m in df_triplet.columns]\n",
    "    for tgt in target_formats:\n",
    "        rows = []\n",
    "        keys_baseline = set(tuple(x) for x in df_triplet[df_triplet[format_col]==baseline_format][['seq', model_col]].values)\n",
    "        keys_target = set(tuple(x) for x in df_triplet[df_triplet[format_col]==tgt][['seq', model_col]].values)\n",
    "        common = sorted(keys_baseline & keys_target)\n",
    "        if not common:\n",
    "            continue\n",
    "        for seq, model in common:\n",
    "            rb = df_triplet[(df_triplet['seq']==seq) & (df_triplet[model_col]==model) & (df_triplet[format_col]==baseline_format)]\n",
    "            rt = df_triplet[(df_triplet['seq']==seq) & (df_triplet[model_col]==model) & (df_triplet[format_col]==tgt)]\n",
    "            if rb.empty or rt.empty:\n",
    "                continue\n",
    "            rb = rb.iloc[0]\n",
    "            rt = rt.iloc[0]\n",
    "            for m in metrics:\n",
    "                v1 = rb[m]  # baseline\n",
    "                v2 = rt[m]  # target\n",
    "                if pd.isna(v1) or pd.isna(v2) or v1 == 0:\n",
    "                    factor = np.nan\n",
    "                else:\n",
    "                    factor = v2 / v1\n",
    "                rows.append({\n",
    "                    'seq': seq,\n",
    "                    model_col: model,\n",
    "                    'baseline_format': baseline_format,\n",
    "                    'target_format': tgt,\n",
    "                    'metric': m,\n",
    "                    'baseline_value': v1,\n",
    "                    'target_value': v2,\n",
    "                    'improvement_factor': factor\n",
    "                })\n",
    "        results[tgt] = pd.DataFrame(rows)\n",
    "    return results\n",
    "\n",
    "def save_factor_tables(factor_results: dict[str,pd.DataFrame], out_dir: str, model_col: str):\n",
    "    for fmt, dfc in factor_results.items():\n",
    "        if dfc.empty: continue\n",
    "        # Filtrar solo métricas permitidas\n",
    "        dfc = dfc[dfc['metric'].isin(ALLOWED_EXPORT_METRICS)]\n",
    "        if dfc.empty: \n",
    "            continue\n",
    "        raw_path = os.path.join(out_dir, f\"format_factor_seq_model_{fmt}.csv\")\n",
    "        dfc.to_csv(raw_path, index=False)\n",
    "        log(f\"Guardado factores detalle: {raw_path}\")\n",
    "        by_model = dfc.groupby([model_col,'metric'])['improvement_factor'].mean().reset_index()\n",
    "        by_model = by_model[by_model['metric'].isin(ALLOWED_EXPORT_METRICS)]\n",
    "        by_model_pivot = by_model.pivot(index=model_col, columns='metric', values='improvement_factor')\n",
    "        by_model_pivot.to_csv(os.path.join(out_dir, f\"format_factor_by_model_{fmt}.csv\"))\n",
    "        by_seq = dfc.groupby(['seq','metric'])['improvement_factor'].mean().reset_index()\n",
    "        by_seq = by_seq[by_seq['metric'].isin(ALLOWED_EXPORT_METRICS)]\n",
    "        by_seq_pivot = by_seq.pivot(index='seq', columns='metric', values='improvement_factor')\n",
    "        by_seq_pivot.to_csv(os.path.join(out_dir, f\"format_factor_by_seq_{fmt}.csv\"))\n",
    "\n",
    "def plot_factor_lines_by_model(factor_results: dict[str,pd.DataFrame],\n",
    "                               out_dir: str,\n",
    "                               model_col: str,\n",
    "                               desired_order_models: list[str],\n",
    "                               figsize=(9,5)):\n",
    "    for fmt, dfc in factor_results.items():\n",
    "        if dfc.empty: continue\n",
    "        pivot = (dfc.groupby([model_col,'metric'])['improvement_factor']\n",
    "                 .mean()\n",
    "                 .unstack('metric'))\n",
    "        if desired_order_models:\n",
    "            present = [m for m in desired_order_models if m in pivot.index]\n",
    "            others = [m for m in pivot.index if m not in present]\n",
    "            pivot = pivot.reindex(present + others)\n",
    "        plt.figure(figsize=figsize)\n",
    "        x = np.arange(len(pivot.index))\n",
    "        for m in pivot.columns:\n",
    "            plt.plot(x, pivot[m].values, marker='o', label=m)\n",
    "        plt.axhline(1.0, color='gray', linestyle='--', linewidth=1)\n",
    "        #plt.xticks(x, pivot.index, rotation=45, ha='right')\n",
    "        plt.xticks(x, pivot.index)\n",
    "        plt.ylabel(\"Factor de mejora (target / baseline)\")\n",
    "        #plt.title(f\"Factor de mejora {fmt} vs {BASELINE_FORMAT} (por modelo)\")\n",
    "        plt.legend(fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        fname = os.path.join(out_dir, f\"factor_lines_{fmt}_by_model.pdf\")\n",
    "        plt.savefig(fname); plt.close()\n",
    "        log(f\"Plot guardado: {fname}\")\n",
    "\n",
    "def plot_factor_lines_by_seq(factor_results: dict[str,pd.DataFrame], out_dir: str, figsize=(9,5)):\n",
    "    for fmt, dfc in factor_results.items():\n",
    "        if dfc.empty: continue\n",
    "        pivot = (dfc.groupby(['seq','metric'])['improvement_factor']\n",
    "                 .mean()\n",
    "                 .unstack('metric'))\n",
    "        plt.figure(figsize=figsize)\n",
    "        x = np.arange(len(pivot.index))\n",
    "        for m in pivot.columns:\n",
    "            plt.plot(x, pivot[m].values, marker='o', label=m)\n",
    "        plt.axhline(1.0, color='gray', linestyle='--', linewidth=1)\n",
    "        #plt.xticks(x, pivot.index, rotation=45, ha='right')\n",
    "        plt.xticks(x, pivot.index)\n",
    "        plt.ylabel(\"Factor de mejora (target / baseline)\")\n",
    "        #plt.title(f\"Factor de mejora {fmt} vs {BASELINE_FORMAT} (por secuencia)\")\n",
    "        plt.legend(fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        fname = os.path.join(out_dir, f\"factor_lines_{fmt}_by_seq.pdf\")\n",
    "        plt.savefig(fname); plt.close()\n",
    "        log(f\"Plot guardado: {fname}\")\n",
    "\n",
    "def plot_specific_model_format_combos(df_triplet: pd.DataFrame,\n",
    "                                      combos: list[tuple[str,str]],\n",
    "                                      model_col: str,\n",
    "                                      format_col: str,\n",
    "                                      metrics: list[str],\n",
    "                                      out_dir: str):\n",
    "    if df_triplet.empty or not combos:\n",
    "        return\n",
    "    ensure_dir(out_dir)\n",
    "    for model, fmt in combos:\n",
    "        subset = df_triplet[(df_triplet[model_col]==model) & (df_triplet[format_col]==fmt)]\n",
    "        if subset.empty:\n",
    "            log(f\"Combo sin datos: ({model}, {fmt})\")\n",
    "            continue\n",
    "        seq_order = [s for s in SEQ_LIST if s in subset['seq'].unique()] + [s for s in subset['seq'].unique() if s not in SEQ_LIST]\n",
    "        metrics_present = [m for m in metrics if m in subset.columns]\n",
    "        if not metrics_present:\n",
    "            continue\n",
    "        plt.figure(figsize=(11,5))\n",
    "        x = np.arange(len(seq_order))\n",
    "        for m in metrics_present:\n",
    "            vals = [subset[subset['seq']==s][m].mean() if not subset[subset['seq']==s].empty else np.nan for s in seq_order]\n",
    "            plt.plot(x, vals, marker='o', label=m)\n",
    "        #plt.xticks(x, seq_order, rotation=45, ha='right')\n",
    "        plt.xticks(x, seq_order)\n",
    "        plt.ylabel(\"Valor\")\n",
    "        plt.title(f\"Métricas por secuencia ({model}, {fmt})\")\n",
    "        plt.legend(fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        fname = os.path.join(out_dir, f\"specific_combo_{model}_{fmt}.pdf\")\n",
    "        plt.savefig(fname); plt.close()\n",
    "        log(f\"Plot guardado: {fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e5820",
   "metadata": {},
   "source": [
    "# Cargar tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5674bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna de formato detectada: export\n",
      "Métricas detectadas (short -> original):\n",
      " - AssA_AUC -> AssA___AUC\n",
      " - IDF1 -> IDF1\n",
      " - HOTA_AUC -> HOTA___AUC\n",
      " - MT -> MT\n",
      " - GT_IDs -> GT_IDs\n",
      " - IDSW -> IDSW\n",
      " - Frag -> Frag\n",
      " - Dets -> Dets\n",
      "Agg map (mean): {'AssA___AUC': 'mean', 'IDF1': 'mean', 'HOTA___AUC': 'mean', 'MT': 'mean', 'GT_IDs': 'mean', 'IDSW': 'mean', 'Frag': 'mean', 'Dets': 'mean'}\n",
      "Guardado: results/model_summary_Tracking1.csv\n",
      "Guardado: results/model_summary_Tracking2.csv\n",
      "Guardado: results/model_summary_Average.csv\n",
      "Guardado: results/format_summary_Tracking1.csv\n",
      "Guardado: results/format_summary_Tracking2.csv\n",
      "Guardado: results/format_summary_Average.csv\n"
     ]
    }
   ],
   "source": [
    "ensure_dir(OUT_DIR)\n",
    "if not os.path.isfile(IN_PATH):\n",
    "    log(f\"ERROR: No existe el archivo: {IN_PATH}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "if 'seq' in df.columns:\n",
    "    df['seq'] = df['seq'].astype(str)\n",
    "\n",
    "model_col = choose_col(df, ['model','export','modelo','Model'])\n",
    "if not model_col:\n",
    "    model_col = df.columns[-1]\n",
    "    log(f\"Advertencia: No se detectó columna 'model'. Usando: {model_col}\")\n",
    "\n",
    "format_col = choose_col(df, ['format','Formato','formato','fmt','format_name', 'export'])\n",
    "if format_col:\n",
    "    df[format_col] = df[format_col].astype(str)\n",
    "    log(f\"Columna de formato detectada: {format_col}\")\n",
    "else:\n",
    "    log(\"No se detectó columna de formato. El análisis por formato será omitido.\")\n",
    "\n",
    "metrics_map = detect_metric_columns(df)\n",
    "log(\"Métricas detectadas (short -> original):\")\n",
    "for k,v in metrics_map.items():\n",
    "    log(f\" - {k} -> {v}\")\n",
    "\n",
    "add_mt_percent(df, metrics_map)\n",
    "\n",
    "numeric_candidates = list(metrics_map.values()) + ['MT_percent']\n",
    "to_numeric_safe(df, [c for c in numeric_candidates if c in df.columns])\n",
    "\n",
    "agg_map = build_agg_map(df, metrics_map)\n",
    "log(f\"Agg map (mean): {agg_map}\")\n",
    "\n",
    "# Agrupaciones por secuencia -> modelo\n",
    "grouped_models_by_seq = {}\n",
    "for seq in SEQ_LIST:\n",
    "    df_seq = df[df['seq'] == seq]\n",
    "    gm = group_and_rename(df_seq, model_col, agg_map, metrics_map)\n",
    "    gm = normalize_and_composite(gm, COMPOSITE_WEIGHTS)\n",
    "    gm = reorder_index(gm, DESIRED_ORDER_MODELS)\n",
    "    grouped_models_by_seq[seq] = gm\n",
    "\n",
    "avg_models = compute_average(grouped_models_by_seq)\n",
    "if not avg_models.empty:\n",
    "    avg_models = normalize_and_composite(avg_models, COMPOSITE_WEIGHTS)\n",
    "    avg_models = reorder_index(avg_models, DESIRED_ORDER_MODELS)\n",
    "    grouped_models_by_seq['Average'] = avg_models\n",
    "else:\n",
    "    grouped_models_by_seq['Average'] = pd.DataFrame()\n",
    "\n",
    "for seq_name, gdf in grouped_models_by_seq.items():\n",
    "    out_csv = os.path.join(OUT_DIR, f\"model_summary_{seq_name}.csv\")\n",
    "    if not gdf.empty:\n",
    "        export_cols = [c for c in ALLOWED_EXPORT_METRICS if c in gdf.columns]\n",
    "        gdf_export = gdf[export_cols]\n",
    "        gdf_export.to_csv(out_csv)\n",
    "        log(f\"Guardado: {out_csv}\")\n",
    "\n",
    "# Agrupaciones por secuencia -> formato\n",
    "grouped_formats_by_seq = {}\n",
    "if format_col:\n",
    "    for seq in SEQ_LIST:\n",
    "        df_seq = df[df['seq'] == seq]\n",
    "        gf = group_and_rename(df_seq, format_col, agg_map, metrics_map)\n",
    "        gf = normalize_and_composite(gf, COMPOSITE_WEIGHTS)\n",
    "        gf = reorder_index(gf, DESIRED_ORDER_FORMATS)\n",
    "        grouped_formats_by_seq[seq] = gf\n",
    "    avg_formats = compute_average(grouped_formats_by_seq)\n",
    "    if not avg_formats.empty:\n",
    "        avg_formats = normalize_and_composite(avg_formats, COMPOSITE_WEIGHTS)\n",
    "        avg_formats = reorder_index(avg_formats, DESIRED_ORDER_FORMATS)\n",
    "        grouped_formats_by_seq['Average'] = avg_formats\n",
    "    else:\n",
    "        grouped_formats_by_seq['Average'] = pd.DataFrame()\n",
    "    for seq_name, gdf in grouped_formats_by_seq.items():\n",
    "        out_csv = os.path.join(OUT_DIR, f\"format_summary_{seq_name}.csv\")\n",
    "        if not gdf.empty:\n",
    "            export_cols = [c for c in ALLOWED_EXPORT_METRICS if c in gdf.columns]\n",
    "            gdf_export = gdf[export_cols]\n",
    "            gdf_export.to_csv(out_csv)\n",
    "            log(f\"Guardado: {out_csv}\")\n",
    "\n",
    "# Tablas (seq, model) y (seq, format)\n",
    "df_seq_model = pd.DataFrame()\n",
    "if 'seq' in df.columns and model_col in df.columns:\n",
    "    numeric_cols = list(agg_map.keys()) + ['MT_percent']\n",
    "    numeric_cols = [c for c in numeric_cols if c in df.columns]\n",
    "    df_seq_model = df[df['seq'].isin(SEQ_LIST)][['seq', model_col] + numeric_cols].copy()\n",
    "    df_seq_model = df_seq_model.groupby(['seq', model_col]).mean().reset_index()\n",
    "    rename_map = {v:k for k,v in metrics_map.items() if v in df_seq_model.columns}\n",
    "    df_seq_model = df_seq_model.rename(columns=rename_map)\n",
    "\n",
    "df_seq_format = pd.DataFrame()\n",
    "if format_col and 'seq' in df.columns:\n",
    "    numeric_cols_f = list(agg_map.keys()) + ['MT_percent']\n",
    "    numeric_cols_f = [c for c in numeric_cols_f if c in df.columns]\n",
    "    df_seq_format = df[df['seq'].isin(SEQ_LIST)][['seq', format_col] + numeric_cols_f].copy()\n",
    "    df_seq_format = df_seq_format.groupby(['seq', format_col]).mean().reset_index()\n",
    "    rename_map_f = {v:k for k,v in metrics_map.items() if v in df_seq_format.columns}\n",
    "    df_seq_format = df_seq_format.rename(columns=rename_map_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b078b9",
   "metadata": {},
   "source": [
    "# Gráficas de Barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18484a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot guardado: results/metricas_clave_modelo_Tracking1.pdf\n",
      "Plot guardado: results/idsw_frag_modelo_Tracking1.pdf\n",
      "Plot guardado: results/metricas_clave_modelo_Tracking2.pdf\n",
      "Plot guardado: results/idsw_frag_modelo_Tracking2.pdf\n",
      "Plot guardado: results/metricas_clave_modelo_Average.pdf\n",
      "Plot guardado: results/idsw_frag_modelo_Average.pdf\n",
      "Plot guardado: results/metricas_clave_formato_Tracking1.pdf\n",
      "Plot guardado: results/idsw_frag_formato_Tracking1.pdf\n",
      "Plot guardado: results/metricas_clave_formato_Tracking2.pdf\n",
      "Plot guardado: results/idsw_frag_formato_Tracking2.pdf\n",
      "Plot guardado: results/metricas_clave_formato_Average.pdf\n",
      "Plot guardado: results/idsw_frag_formato_Average.pdf\n"
     ]
    }
   ],
   "source": [
    "# Gráficas modelos / formatos\n",
    "figsize = (8, 3)\n",
    "plot_metrics = [m for m in ['IDF1','AssA_AUC','HOTA_AUC','MT_percent'] if any((m in g.columns) for g in grouped_models_by_seq.values())]\n",
    "for seq_name, gdf in grouped_models_by_seq.items():\n",
    "    if gdf.empty: continue\n",
    "    plot_group_bars(gdf, seq_name, \"modelo\", DESIRED_ORDER_MODELS, plot_metrics, OUT_DIR, figsize)\n",
    "    plot_idsw_frag(gdf, seq_name, \"modelo\", DESIRED_ORDER_MODELS, OUT_DIR, figsize)\n",
    "\n",
    "if format_col:\n",
    "    plot_metrics_fmt = [m for m in ['IDF1','AssA_AUC','HOTA_AUC','MT_percent'] if any((m in g.columns) for g in grouped_formats_by_seq.values())]\n",
    "    for seq_name, gdf in grouped_formats_by_seq.items():\n",
    "        if gdf.empty: continue\n",
    "        plot_group_bars(gdf, seq_name, \"formato\", DESIRED_ORDER_FORMATS, plot_metrics_fmt, OUT_DIR, figsize)\n",
    "        plot_idsw_frag(gdf, seq_name, \"formato\", DESIRED_ORDER_FORMATS, OUT_DIR, figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1811bfe",
   "metadata": {},
   "source": [
    "# Curvas IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8acd0c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot guardado: results/assa_vs_iou_model_Tracking1.pdf\n",
      "Plot guardado: results/deta_vs_iou_model_Tracking1.pdf\n",
      "Plot guardado: results/assa_vs_iou_format_Tracking1.pdf\n",
      "Plot guardado: results/deta_vs_iou_format_Tracking1.pdf\n",
      "Plot guardado: results/assa_vs_iou_model_Tracking2.pdf\n",
      "Plot guardado: results/deta_vs_iou_model_Tracking2.pdf\n",
      "Plot guardado: results/assa_vs_iou_format_Tracking2.pdf\n",
      "Plot guardado: results/deta_vs_iou_format_Tracking2.pdf\n",
      "Plot guardado: results/assa_vs_iou_model_Average.pdf\n",
      "Plot guardado: results/deta_vs_iou_model_Average.pdf\n",
      "Plot guardado: results/assa_vs_iou_format_Average.pdf\n",
      "Plot guardado: results/deta_vs_iou_format_Average.pdf\n"
     ]
    }
   ],
   "source": [
    "# Curvas IoU\n",
    "ass_cols = [c for c in df.columns if c.startswith(ASSA_PREFIX) and c.split(\"___\")[-1].isdigit()]\n",
    "det_cols = [c for c in df.columns if c.startswith(DETA_PREFIX) and c.split(\"___\")[-1].isdigit()]\n",
    "thresholds_ass = [int(c.split(\"___\")[-1]) for c in ass_cols]\n",
    "thresholds_det = [int(c.split(\"___\")[-1]) for c in det_cols]\n",
    "figsize = (5, 3)\n",
    "\n",
    "for seq in SEQ_LIST:\n",
    "    df_seq = df[df['seq'] == seq]\n",
    "    if df_seq.empty: continue\n",
    "    if ass_cols:\n",
    "        plot_curves_by_iou(df_seq, model_col, \"AssA\", thresholds_ass, ass_cols, DESIRED_ORDER_MODELS, \"AssA\", \"model\", seq, OUT_DIR, figsize)\n",
    "    if det_cols:\n",
    "        plot_curves_by_iou(df_seq, model_col, \"DetA\", thresholds_det, det_cols, DESIRED_ORDER_MODELS, \"DetA\", \"model\", seq, OUT_DIR, figsize)\n",
    "    if format_col:\n",
    "        if ass_cols:\n",
    "            plot_curves_by_iou(df_seq, format_col, \"AssA\", thresholds_ass, ass_cols, DESIRED_ORDER_FORMATS, \"AssA\", \"format\", seq, OUT_DIR, figsize)\n",
    "        if det_cols:\n",
    "            plot_curves_by_iou(df_seq, format_col, \"DetA\", thresholds_det, det_cols, DESIRED_ORDER_FORMATS, \"DetA\", \"format\", seq, OUT_DIR, figsize)\n",
    "\n",
    "if ass_cols:\n",
    "    m_ass = df[df['seq'].isin(SEQ_LIST)].groupby(['seq', model_col])[ass_cols].mean()\n",
    "    avg_ass = m_ass.groupby(model_col).mean().reset_index()\n",
    "    plot_curves_by_iou(avg_ass, model_col, \"AssA\", thresholds_ass, ass_cols, DESIRED_ORDER_MODELS, \"AssA\", \"model\", \"Average\", OUT_DIR, figsize)\n",
    "if det_cols:\n",
    "    m_det = df[df['seq'].isin(SEQ_LIST)].groupby(['seq', model_col])[det_cols].mean()\n",
    "    avg_det = m_det.groupby(model_col).mean().reset_index()\n",
    "    plot_curves_by_iou(avg_det, model_col, \"DetA\", thresholds_det, det_cols, DESIRED_ORDER_MODELS, \"DetA\", \"model\", \"Average\", OUT_DIR, figsize)\n",
    "\n",
    "if format_col:\n",
    "    if ass_cols:\n",
    "        f_ass = df[df['seq'].isin(SEQ_LIST)].groupby(['seq', format_col])[ass_cols].mean()\n",
    "        avg_f_ass = f_ass.groupby(format_col).mean().reset_index()\n",
    "        plot_curves_by_iou(avg_f_ass, format_col, \"AssA\", thresholds_ass, ass_cols, DESIRED_ORDER_FORMATS, \"AssA\", \"format\", \"Average\", OUT_DIR, figsize)\n",
    "    if det_cols:\n",
    "        f_det = df[df['seq'].isin(SEQ_LIST)].groupby(['seq', format_col])[det_cols].mean()\n",
    "        avg_f_det = f_det.groupby(format_col).mean().reset_index()\n",
    "        plot_curves_by_iou(avg_f_det, format_col, \"DetA\", thresholds_det, det_cols, DESIRED_ORDER_FORMATS, \"DetA\", \"format\", \"Average\", OUT_DIR, figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4d997",
   "metadata": {},
   "source": [
    "# Mapas de Calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a5eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap guardado: results/seq_model_composite_heatmap.pdf\n",
      "Heatmap guardado: results/seq_format_composite_heatmap.pdf\n"
     ]
    }
   ],
   "source": [
    "# Heatmaps composite\n",
    "model_composite_rows = []\n",
    "for seq_name, gdf in grouped_models_by_seq.items():\n",
    "    if gdf.empty: continue\n",
    "    for idx, row in gdf.iterrows():\n",
    "        model_composite_rows.append({'seq': seq_name, 'model': idx, 'composite_score': row.get('composite_score', np.nan)})\n",
    "model_comp_df = pd.DataFrame(model_composite_rows)\n",
    "pivot_models = pd.DataFrame()\n",
    "if not model_comp_df.empty:\n",
    "    pivot_models = model_comp_df.pivot(index='seq', columns='model', values='composite_score')\n",
    "    cols_order = [c for c in DESIRED_ORDER_MODELS if c in pivot_models.columns]\n",
    "    other_cols = [c for c in pivot_models.columns if c not in cols_order]\n",
    "    pivot_models = pivot_models[cols_order + other_cols]\n",
    "    pivot_path = os.path.join(OUT_DIR, \"seq_model_composite_matrix.csv\")\n",
    "    pivot_models.to_csv(pivot_path)\n",
    "    heatmap_path = os.path.join(OUT_DIR, \"seq_model_composite_heatmap.pdf\")\n",
    "    heatmap(pivot_models, \"Heatmap composite modelos\", heatmap_path)\n",
    "\n",
    "if format_col and grouped_formats_by_seq:\n",
    "    format_composite_rows = []\n",
    "    for seq_name, gdf in grouped_formats_by_seq.items():\n",
    "        if gdf.empty: continue\n",
    "        for idx, row in gdf.iterrows():\n",
    "            format_composite_rows.append({'seq': seq_name, 'format': idx, 'composite_score': row.get('composite_score', np.nan)})\n",
    "    format_comp_df = pd.DataFrame(format_composite_rows)\n",
    "    if not format_comp_df.empty:\n",
    "        pivot_formats = format_comp_df.pivot(index='seq', columns='format', values='composite_score')\n",
    "        cols_order_f = [c for c in DESIRED_ORDER_FORMATS if c in pivot_formats.columns]\n",
    "        other_cols_f = [c for c in pivot_formats.columns if c not in cols_order_f]\n",
    "        pivot_formats = pivot_formats[cols_order_f + other_cols_f]\n",
    "        pivot_f_path = os.path.join(OUT_DIR, \"seq_format_composite_matrix.csv\")\n",
    "        pivot_formats.to_csv(pivot_f_path)\n",
    "        heatmap_f_path = os.path.join(OUT_DIR, \"seq_format_composite_heatmap.pdf\")\n",
    "        heatmap(pivot_formats, \"Heatmap composite formatos\", heatmap_f_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d639e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rankings\n",
    "if not pivot_models.empty:\n",
    "    avg_model_scores = pivot_models.loc[[r for r in pivot_models.index if r != 'Average']].mean(axis=0).sort_values(ascending=False)\n",
    "    avg_model_scores.to_csv(os.path.join(OUT_DIR, \"ranking_modelos_promedio.csv\"), header=['mean_composite'])\n",
    "if format_col and 'Average' in grouped_formats_by_seq and not grouped_formats_by_seq['Average'].empty:\n",
    "    fmt_avg = grouped_formats_by_seq['Average']\n",
    "    fmt_avg[['composite_score']].sort_values('composite_score', ascending=False).to_csv(\n",
    "        os.path.join(OUT_DIR, \"ranking_formatos_average.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159363f",
   "metadata": {},
   "source": [
    "# Factor de Mejora entre formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2f4cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado factores detalle: results/format_factor_seq_model_FP16.csv\n",
      "Guardado factores detalle: results/format_factor_seq_model_INT8.csv\n",
      "Plot guardado: results/factor_lines_FP16_by_model.pdf\n",
      "Plot guardado: results/factor_lines_INT8_by_model.pdf\n",
      "Plot guardado: results/factor_lines_FP16_by_seq.pdf\n",
      "Plot guardado: results/factor_lines_INT8_by_seq.pdf\n",
      "Análisis completado. Resultados en: results\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# FACTOR DE MEJORA ENTRE FORMATOS\n",
    "# =====================================================\n",
    "if format_col:\n",
    "    df_triplet = aggregate_seq_model_format(df, SEQ_LIST, model_col, format_col, metrics_map)\n",
    "    if not df_triplet.empty:\n",
    "        comparison_metrics = [m for m in COMPARISON_METRICS_CANDIDATES if m in df_triplet.columns]\n",
    "        factor_results = compute_format_factor(\n",
    "            df_triplet=df_triplet,\n",
    "            model_col=model_col,\n",
    "            format_col=format_col,\n",
    "            baseline_format=BASELINE_FORMAT,\n",
    "            target_formats=[f for f in COMPARISON_TARGET_FORMATS if f in df_triplet[format_col].unique()],\n",
    "            metrics=comparison_metrics\n",
    "        )\n",
    "        if factor_results:\n",
    "            save_factor_tables(factor_results, OUT_DIR, model_col)\n",
    "            plot_factor_lines_by_model(factor_results, OUT_DIR, model_col, DESIRED_ORDER_MODELS)\n",
    "            plot_factor_lines_by_seq(factor_results, OUT_DIR)\n",
    "\n",
    "        # Gráficas para combos específicos\n",
    "        if SPECIFIC_MODEL_FORMATS:\n",
    "            plot_specific_model_format_combos(\n",
    "                df_triplet=df_triplet,\n",
    "                combos=SPECIFIC_MODEL_FORMATS,\n",
    "                model_col=model_col,\n",
    "                format_col=format_col,\n",
    "                metrics=comparison_metrics,\n",
    "                out_dir=OUT_DIR\n",
    "            )\n",
    "    else:\n",
    "        log(\"No se pudo crear df_triplet para factores de formato.\")\n",
    "\n",
    "log(f\"Análisis completado. Resultados en: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb695a",
   "metadata": {},
   "source": [
    "# LaTex Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebc4939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def csv_a_latex(csv_path: str,\n",
    "                dec: int = 2,\n",
    "                cols: list[str] | None = None,\n",
    "                index: bool = False,\n",
    "                na: str = '',\n",
    "                max_w: int | None = None,\n",
    "                out_path: str | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Convierte un CSV en tabla LaTeX.\n",
    "    - Redondeo a 'dec' decimales.\n",
    "    - Selección de columnas.\n",
    "    - Truncado opcional de texto.\n",
    "    - Renombra columnas:\n",
    "        * Elimina sufijo '_AUC'\n",
    "        * MT_percent -> MT\\\\%\n",
    "    - Renombra valores de formatos:\n",
    "        * FP16 -> TensorRT-FP16\n",
    "        * INT8 -> TensorRT-INT8\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(csv_path):\n",
    "        log(f\"No existe: {csv_path}\")\n",
    "        return \"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Si viene índice exportado como primera columna tipo 'Unnamed: 0', intentar usarlo\n",
    "    if 'Unnamed: 0' in df.columns and 'format' not in df.columns and 'model' not in df.columns:\n",
    "        df = df.rename(columns={'Unnamed: 0': 'index_label'})\n",
    "\n",
    "    # Filtrar columnas deseadas\n",
    "    if cols:\n",
    "        keep = [c for c in cols if c in df.columns]\n",
    "        if keep:\n",
    "            df = df[keep]\n",
    "\n",
    "    # Renombrar columnas (_AUC fuera y MT_percent -> MT\\%)\n",
    "    rename_cols = {}\n",
    "    for c in df.columns:\n",
    "        new_c = c\n",
    "        if new_c.endswith('_AUC'):\n",
    "            new_c = new_c[:-4]  # quitar _AUC\n",
    "        if new_c == 'MT_percent':\n",
    "            new_c = 'MT\\\\%'\n",
    "        rename_cols[c] = new_c\n",
    "    df = df.rename(columns=rename_cols)\n",
    "\n",
    "    # Map de formatos\n",
    "    format_map = {\n",
    "        'FP16': 'TensorRT-FP16',\n",
    "        'INT8': 'TensorRT-INT8',\n",
    "        'Pytorch': 'Pytorch'\n",
    "    }\n",
    "\n",
    "    # Aplicar renombre si existe columna de formato\n",
    "    for possible in ['format', 'Formato', 'formato']:\n",
    "        if possible in df.columns:\n",
    "            df[possible] = df[possible].replace(format_map)\n",
    "    # También intentar sobre el índice si procede\n",
    "    try:\n",
    "        df.index = df.index.to_series().replace(format_map).values\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Redondeo numérico\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(num_cols):\n",
    "        df[num_cols] = df[num_cols].round(dec)\n",
    "\n",
    "    # Truncar texto\n",
    "    if max_w:\n",
    "        for c in df.columns:\n",
    "            if c not in num_cols:\n",
    "                df[c] = df[c].astype(str).map(lambda v: v if len(v) <= max_w else v[:max_w-1] + '…')\n",
    "\n",
    "    fmt = lambda x: f\"{x:.{dec}f}\"\n",
    "    latex = df.to_latex(index=index, float_format=fmt, na_rep=na, escape=False)\n",
    "\n",
    "    if out_path:\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(latex)\n",
    "        log(f\"Tabla LaTeX guardada: {out_path}\")\n",
    "    return latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d40d6f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "model & IDF1 & AssA & HOTA & MT\\% & IDSW & Frag \\\\\n",
      "\\midrule\n",
      "Salmones2024 & 0.642824 & 0.534584 & 0.488566 & 0.274775 & 11.333333 & 29.000000 \\\\\n",
      "yolov8m & 0.377577 & 0.363339 & 0.287797 & 0.009009 & 5.500000 & 29.666667 \\\\\n",
      "yolov8l & 0.389989 & 0.391296 & 0.304429 & 0.049550 & 5.833333 & 26.000000 \\\\\n",
      "yolov9c & 0.313651 & 0.367838 & 0.257206 & 0.018018 & 5.666667 & 15.166667 \\\\\n",
      "yolo11m & 0.411761 & 0.438106 & 0.341444 & 0.063063 & 4.833333 & 16.833333 \\\\\n",
      "yolo11l & 0.373115 & 0.397294 & 0.299152 & 0.072072 & 6.666667 & 20.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"results/model_summary_Tracking2.csv\"\n",
    "latex_text = csv_a_latex(csv_path=csv_path, dec=6, index=False, na='-')\n",
    "print(latex_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memoria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
