{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf37c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas detectadas:\n",
      " model_col: model\n",
      " AssA_AUC: AssA___AUC\n",
      " IDF1: IDF1\n",
      " HOTA_AUC: HOTA___AUC\n",
      " MT: MT\n",
      " GT_IDs: GT_IDs\n",
      " IDSW: IDSW\n",
      " Frag: Frag\n",
      " Dets: Dets\n",
      "Métricas mapeadas:\n",
      " - AssA_AUC -> AssA___AUC\n",
      " - IDF1 -> IDF1\n",
      " - HOTA_AUC -> HOTA___AUC\n",
      " - MT -> MT\n",
      " - GT_IDs -> GT_IDs\n",
      " - IDSW -> IDSW\n",
      " - Frag -> Frag\n",
      " - Dets -> Dets\n",
      " - MT_percent -> MT_percent\n",
      "Agg map (columnas numéricas que se usarán para mean):\n",
      "{'AssA___AUC': 'mean', 'IDF1': 'mean', 'HOTA___AUC': 'mean', 'MT': 'mean', 'GT_IDs': 'mean', 'IDSW': 'mean', 'Frag': 'mean', 'Dets': 'mean', 'MT_percent': 'mean'}\n",
      "Guardado: results/model_summary_Tracking1.csv\n",
      "Guardado: results/model_summary_Tracking2.csv\n",
      "Guardado: results/model_summary_Average.csv\n",
      "Plot guardado: results/metricas_clave_por_modelo_Tracking1.pdf\n",
      "Plot guardado: results/metricas_clave_por_modelo_Tracking2.pdf\n",
      "Plot guardado: results/metricas_clave_por_modelo_Average.pdf\n",
      "Saved: results/assa_vs_iou_Tracking1.pdf\n",
      "Saved: results/deta_vs_iou_Tracking1.pdf\n",
      "Saved: results/assa_vs_iou_Tracking2.pdf\n",
      "Saved: results/deta_vs_iou_Tracking2.pdf\n",
      "Saved: results/assa_vs_iou_Average.pdf\n",
      "Saved: results/deta_vs_iou_Average.pdf\n",
      "Saved: results/idsw_frag_por_modelo_Tracking1.pdf\n",
      "Saved: results/idsw_frag_por_modelo_Tracking2.pdf\n",
      "Saved: results/idsw_frag_por_modelo_Average.pdf\n",
      "Guardado pivot: results/seq_model_composite_matrix_tracking12.csv\n",
      "Saved heatmap: results/seq_model_composite_heatmap_tracking12.pdf\n",
      "Guardado seq rankings: results/seq_model_rankings_tracking12.csv\n",
      "Análisis completado. Resultados en: results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27486/3156216220.py:385: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_out = df_out.groupby('seq').apply(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Análisis de tracking para Tracking1, Tracking2 y Average(Tracking1,Tracking2).\n",
    "- Detecta columnas relevantes del CSV.\n",
    "- Convierte las columnas métricas a numérico (coerce).\n",
    "- Agrupa por modelo y por (seq, model).\n",
    "- Calcula composite_score basado en métricas de asociación/identidad.\n",
    "- Genera CSVs y PDFs con gráficas, forzando orden de modelos:\n",
    "    Salmones2024, yolov8m, yolov8l, yolov9c, yolo11m, yolo11l\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "IN_PATH = \"combined_results.csv\"           # Cambia si tu CSV está en otra ruta\n",
    "OUT_DIR = \"results\"             # Carpeta de salida\n",
    "SEQ_LIST = [\"Tracking1\", \"Tracking2\"]      # Secuencias objetivo\n",
    "DESIRED_ORDER = ['Salmones2024','yolov8m','yolov8l','yolov9c','yolo11m','yolo11l']\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Aesthetic matplotlib\n",
    "plt.style.use('default')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({\n",
    "    'figure.facecolor': 'white',\n",
    "    'figure.edgecolor': 'white',\n",
    "    'axes.facecolor': 'white',\n",
    "    'axes.edgecolor': 'black',\n",
    "    'axes.labelcolor': 'black',\n",
    "    'xtick.color': 'black',\n",
    "    'ytick.color': 'black',\n",
    "    'text.color': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.edgecolor': 'black',\n",
    "    'savefig.facecolor': 'white',\n",
    "    'savefig.edgecolor': 'white',\n",
    "    'savefig.transparent': False,\n",
    "})\n",
    "\n",
    "# -----------------------\n",
    "# Lectura y detección de columnas\n",
    "# -----------------------\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "# Asegurar seq como string si existe\n",
    "if 'seq' in df.columns:\n",
    "    df['seq'] = df['seq'].astype(str)\n",
    "\n",
    "def choose_col(df, preferred_list):\n",
    "    \"\"\"Elige la columna exacta o la primera que contiene el substring.\"\"\"\n",
    "    for p in preferred_list:\n",
    "        if p in df.columns:\n",
    "            return p\n",
    "    for p in preferred_list:\n",
    "        matches = [c for c in df.columns if p.lower() in c.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    return None\n",
    "\n",
    "# detectar columna de modelo/export\n",
    "model_col = 'model' if 'model' in df.columns else ('export' if 'export' in df.columns else df.columns[-1])\n",
    "\n",
    "# detectar métricas importantes (intenta varios nombres)\n",
    "assauc_col   = choose_col(df, ['AssA___AUC','AssA_AUC','AssA___AUC','AssA AUC','AssA'])\n",
    "idf1_col     = choose_col(df, ['IDF1','IDF_1','ID_F1'])\n",
    "hota_auc_col = choose_col(df, ['HOTA___AUC','HOTA_AUC','HOTA___AUC','HOTA'])\n",
    "mt_col       = choose_col(df, ['MT','MTR','Mostly-Tracked','MostlyTracked'])\n",
    "gt_ids_col   = choose_col(df, ['GT_IDs','GT_IDS','GT_ID','GT_IDs','GT_ID'])\n",
    "idsw_col     = choose_col(df, ['IDSW','ID Sw','ID_Switches','id switches'])\n",
    "frag_col     = choose_col(df, ['Frag','Fragmentation','FRAG'])\n",
    "dets_col     = choose_col(df, ['Dets','Detections','GT_Dets','Dets '])\n",
    "\n",
    "print(\"Columnas detectadas:\")\n",
    "print(\" model_col:\", model_col)\n",
    "print(\" AssA_AUC:\", assauc_col)\n",
    "print(\" IDF1:\", idf1_col)\n",
    "print(\" HOTA_AUC:\", hota_auc_col)\n",
    "print(\" MT:\", mt_col)\n",
    "print(\" GT_IDs:\", gt_ids_col)\n",
    "print(\" IDSW:\", idsw_col)\n",
    "print(\" Frag:\", frag_col)\n",
    "print(\" Dets:\", dets_col)\n",
    "\n",
    "# -----------------------\n",
    "# Crear MT_percent si es posible\n",
    "# -----------------------\n",
    "if mt_col and gt_ids_col and mt_col in df.columns and gt_ids_col in df.columns:\n",
    "    # Convertimos los dos a numérico para evitar problemas\n",
    "    df[mt_col] = pd.to_numeric(df[mt_col], errors='coerce')\n",
    "    df[gt_ids_col] = pd.to_numeric(df[gt_ids_col], errors='coerce')\n",
    "    df['MT_percent'] = df[mt_col] / df[gt_ids_col].replace({0: np.nan})\n",
    "else:\n",
    "    df['MT_percent'] = np.nan\n",
    "\n",
    "# -----------------------\n",
    "# Mapear métricas disponibles (short name -> actual column)\n",
    "# -----------------------\n",
    "metrics_map = {}\n",
    "candidates = [\n",
    "    ('AssA_AUC', assauc_col),\n",
    "    ('IDF1', idf1_col),\n",
    "    ('HOTA_AUC', hota_auc_col),\n",
    "    ('MT', mt_col),\n",
    "    ('GT_IDs', gt_ids_col),\n",
    "    ('IDSW', idsw_col),\n",
    "    ('Frag', frag_col),\n",
    "    ('Dets', dets_col),\n",
    "    ('MT_percent', 'MT_percent')\n",
    "]\n",
    "for short, col in candidates:\n",
    "    if col and (col in df.columns or col == 'MT_percent'):\n",
    "        metrics_map[short] = col\n",
    "\n",
    "print(\"Métricas mapeadas:\")\n",
    "for k,v in metrics_map.items():\n",
    "    print(\" -\", k, \"->\", v)\n",
    "\n",
    "# -----------------------\n",
    "# Conversión a numérico de columnas métricas detectadas\n",
    "# -----------------------\n",
    "numeric_cols_to_try = [v for v in metrics_map.values() if v in df.columns]\n",
    "for c in numeric_cols_to_try:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# -----------------------\n",
    "# Construir agg_map seguro (solo columnas numéricas)\n",
    "# -----------------------\n",
    "def agg_map_from_metrics(metrics_map, df):\n",
    "    cols = [v for v in metrics_map.values() if v in df.columns and pd.api.types.is_numeric_dtype(df[v])]\n",
    "    return {col: 'mean' for col in cols}\n",
    "\n",
    "agg_map = agg_map_from_metrics(metrics_map, df)\n",
    "print(\"Agg map (columnas numéricas que se usarán para mean):\")\n",
    "print(agg_map)\n",
    "\n",
    "# -----------------------\n",
    "# Funciones utilitarias\n",
    "# -----------------------\n",
    "def compute_grouped_model(df_sub, model_col, agg_map, metrics_map):\n",
    "    \"\"\"Agrupa df_sub por modelo, usando agg_map seguro, y renombra a short names.\"\"\"\n",
    "    if df_sub.empty:\n",
    "        return pd.DataFrame()\n",
    "    agg_map_sub = {k:v for k,v in agg_map.items() if k in df_sub.columns}\n",
    "    if not agg_map_sub:\n",
    "        return pd.DataFrame()\n",
    "    grp = df_sub.groupby(model_col).agg(agg_map_sub)\n",
    "    # rename a short names donde proceda\n",
    "    rename_map = {v:k for k,v in metrics_map.items() if v in grp.columns}\n",
    "    grp = grp.rename(columns=rename_map)\n",
    "    return grp\n",
    "\n",
    "def add_composite_score(grouped_model):\n",
    "    \"\"\"Anexa columnas normalizadas y composite_score (0..1).\"\"\"\n",
    "    gm = grouped_model.copy()\n",
    "    if gm.empty:\n",
    "        return gm\n",
    "    gm = gm.fillna(0)\n",
    "    norm_cols = [c for c in ['AssA_AUC','IDF1','HOTA_AUC','MT_percent','IDSW','Frag'] if c in gm.columns]\n",
    "    if norm_cols:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(gm[norm_cols])\n",
    "        scaled_df = pd.DataFrame(scaled, index=gm.index, columns=[c + \"_norm\" for c in norm_cols])\n",
    "        gm = pd.concat([gm, scaled_df], axis=1)\n",
    "    weights = {\n",
    "        'AssA_AUC_norm': 0.35,\n",
    "        'IDF1_norm': 0.25,\n",
    "        'HOTA_AUC_norm': 0.15,\n",
    "        'MT_percent_norm': 0.10,\n",
    "        'IDSW_norm': -0.10,\n",
    "        'Frag_norm': -0.10\n",
    "    }\n",
    "    used_weights = {k:w for k,w in weights.items() if k in gm.columns}\n",
    "    score = np.zeros(len(gm))\n",
    "    for k,w in used_weights.items():\n",
    "        score += w * gm[k].values\n",
    "    if score.max() > score.min():\n",
    "        score_norm = (score - score.min())/(score.max()-score.min())\n",
    "    else:\n",
    "        score_norm = np.zeros_like(score)\n",
    "    gm['composite_score_raw'] = score\n",
    "    gm['composite_score'] = score_norm\n",
    "    return gm\n",
    "\n",
    "def reorder_df_index(df_in, order):\n",
    "    if df_in.empty:\n",
    "        return df_in\n",
    "    present = [m for m in order if m in df_in.index]\n",
    "    others = [m for m in df_in.index if m not in present]\n",
    "    return df_in.reindex(present + others)\n",
    "\n",
    "def safe_get_vals(df_g, metric, model_order):\n",
    "    vals = []\n",
    "    for m in model_order:\n",
    "        if m in df_g.index and metric in df_g.columns:\n",
    "            vals.append(df_g.loc[m, metric])\n",
    "        else:\n",
    "            vals.append(np.nan)\n",
    "    return vals\n",
    "\n",
    "# -----------------------\n",
    "# 1) Agrupar por secuencia (Tracking1, Tracking2)\n",
    "# -----------------------\n",
    "grouped_by_seq = {}\n",
    "for seq in SEQ_LIST:\n",
    "    df_sub = df[df['seq'] == seq]\n",
    "    grouped_by_seq[seq] = compute_grouped_model(df_sub, model_col, agg_map, metrics_map)\n",
    "\n",
    "# -----------------------\n",
    "# 2) Crear df_seq_model (solo columnas numéricas) y calcular Average por modelo\n",
    "# -----------------------\n",
    "if agg_map:\n",
    "    # numeric_agg_cols son las columnas reales en df que son numéricas\n",
    "    numeric_agg_cols = list(agg_map.keys())\n",
    "    # Conservar solo 'seq', model_col y las columnas numéricas\n",
    "    df_seq_model = df[df['seq'].isin(SEQ_LIST)][['seq', model_col] + numeric_agg_cols].copy()\n",
    "    # Agrupar por (seq, model) sobre esas columnas numéricas\n",
    "    df_seq_model = df_seq_model.groupby(['seq', model_col]).mean().reset_index()\n",
    "    # Renombrar a short names donde aplique\n",
    "    rename_map = {v:k for k,v in metrics_map.items() if v in df_seq_model.columns}\n",
    "    if rename_map:\n",
    "        df_seq_model = df_seq_model.rename(columns=rename_map)\n",
    "else:\n",
    "    df_seq_model = pd.DataFrame(columns=['seq', model_col])\n",
    "\n",
    "# Calcular Average: promedio (por modelo) de las columnas numéricas existentes (usando short names)\n",
    "if not df_seq_model.empty:\n",
    "    numeric_short_cols = [k for k in metrics_map.keys() if k in df_seq_model.columns]\n",
    "    grouped_by_seq['Average'] = df_seq_model.groupby(model_col)[numeric_short_cols].mean()\n",
    "else:\n",
    "    grouped_by_seq['Average'] = pd.DataFrame()\n",
    "\n",
    "# Añadir composite score y reordenar índices\n",
    "for key in list(grouped_by_seq.keys()):\n",
    "    grouped_by_seq[key] = add_composite_score(grouped_by_seq[key])\n",
    "    grouped_by_seq[key] = reorder_df_index(grouped_by_seq[key], DESIRED_ORDER)\n",
    "\n",
    "# Guardar CSV resumen por modelo para cada vista\n",
    "for key, gm in grouped_by_seq.items():\n",
    "    out_path = os.path.join(OUT_DIR, f\"model_summary_{key}.csv\")\n",
    "    gm.sort_values('composite_score', ascending=False).to_csv(out_path)\n",
    "    print(\"Guardado:\", out_path)\n",
    "\n",
    "# -----------------------\n",
    "# Plots: métricas clave por modelo (IDF1, AssA_AUC, HOTA_AUC, MT_percent)\n",
    "# -----------------------\n",
    "plot_metrics = [c for c in ['IDF1','AssA_AUC','HOTA_AUC','MT_percent'] if any(c in grouped_by_seq[k].columns for k in grouped_by_seq)]\n",
    "for key in list(grouped_by_seq.keys()):\n",
    "    gm = grouped_by_seq[key]\n",
    "    if gm is None or gm.empty:\n",
    "        continue\n",
    "    x = np.arange(len(DESIRED_ORDER))\n",
    "    plt.figure(figsize=(10,6))\n",
    "    width = 0.15\n",
    "    n = len(plot_metrics)\n",
    "    for i, metric in enumerate(plot_metrics):\n",
    "        vals = safe_get_vals(gm, metric, DESIRED_ORDER)\n",
    "        plt.bar(x + (i-(n-1)/2)*width, vals, width, label=metric)\n",
    "    plt.xticks(x, DESIRED_ORDER, rotation=45, ha='right')\n",
    "    plt.ylabel(\"Valor medio (por seq)\")\n",
    "    plt.title(f\"Comparación métricas clave por modelo - {key}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    p = os.path.join(OUT_DIR, f\"metricas_clave_por_modelo_{key}.pdf\")\n",
    "    plt.savefig(p)\n",
    "    plt.close()\n",
    "    print(\"Plot guardado:\", p)\n",
    "\n",
    "# -----------------------\n",
    "# Curvas AssA & DetA por IoU (por seq y Average)\n",
    "# -----------------------\n",
    "ass_cols = [c for c in df.columns if c.startswith(\"AssA___\") and c.split(\"___\")[-1].isdigit()]\n",
    "det_cols = [c for c in df.columns if c.startswith(\"DetA___\") and c.split(\"___\")[-1].isdigit()]\n",
    "\n",
    "thresholds_ass = [int(c.split(\"___\")[-1]) for c in ass_cols] if ass_cols else []\n",
    "thresholds_det = [int(c.split(\"___\")[-1]) for c in det_cols] if det_cols else []\n",
    "\n",
    "# Por cada seq\n",
    "for seq in SEQ_LIST:\n",
    "    df_sub = df[df['seq'] == seq]\n",
    "    if df_sub.empty:\n",
    "        continue\n",
    "    if ass_cols:\n",
    "        mean_by_model_ass = df_sub.groupby(model_col)[ass_cols].mean()\n",
    "        plt.figure(figsize=(8,5))\n",
    "        for m in DESIRED_ORDER:\n",
    "            if m in mean_by_model_ass.index:\n",
    "                plt.plot(thresholds_ass, mean_by_model_ass.loc[m].values, marker='o', label=m)\n",
    "        plt.xlabel(\"IoU threshold (%)\"); plt.ylabel(\"AssA\"); plt.title(f\"AssA vs IoU - {seq}\")\n",
    "        plt.legend(); plt.tight_layout()\n",
    "        p = os.path.join(OUT_DIR, f\"assa_vs_iou_{seq}.pdf\"); plt.savefig(p); plt.close(); print(\"Saved:\", p)\n",
    "    if det_cols:\n",
    "        mean_by_model_det = df_sub.groupby(model_col)[det_cols].mean()\n",
    "        plt.figure(figsize=(8,5))\n",
    "        for m in DESIRED_ORDER:\n",
    "            if m in mean_by_model_det.index:\n",
    "                plt.plot(thresholds_det, mean_by_model_det.loc[m].values, marker='o', label=m)\n",
    "        plt.xlabel(\"IoU threshold (%)\"); plt.ylabel(\"DetA\"); plt.title(f\"DetA vs IoU - {seq}\")\n",
    "        plt.legend(); plt.tight_layout()\n",
    "        p = os.path.join(OUT_DIR, f\"deta_vs_iou_{seq}.pdf\"); plt.savefig(p); plt.close(); print(\"Saved:\", p)\n",
    "\n",
    "# Curvas promedio (Average) calculadas promediando curvas por seq\n",
    "if ass_cols or det_cols:\n",
    "    mean_seq_model_ass = df[df['seq'].isin(SEQ_LIST)].groupby(['seq', model_col])[ass_cols].mean() if ass_cols else None\n",
    "    mean_seq_model_det = df[df['seq'].isin(SEQ_LIST)].groupby(['seq', model_col])[det_cols].mean() if det_cols else None\n",
    "    if ass_cols and mean_seq_model_ass is not None:\n",
    "        avg_ass = mean_seq_model_ass.groupby(model_col).mean()\n",
    "        plt.figure(figsize=(8,5))\n",
    "        for m in DESIRED_ORDER:\n",
    "            if m in avg_ass.index:\n",
    "                plt.plot(thresholds_ass, avg_ass.loc[m].values, marker='o', label=m)\n",
    "        plt.xlabel(\"IoU threshold (%)\"); plt.ylabel(\"AssA\"); plt.title(\"AssA vs IoU - Average\")\n",
    "        plt.legend(); plt.tight_layout()\n",
    "        p = os.path.join(OUT_DIR, f\"assa_vs_iou_Average.pdf\"); plt.savefig(p); plt.close(); print(\"Saved:\", p)\n",
    "    if det_cols and mean_seq_model_det is not None:\n",
    "        avg_det = mean_seq_model_det.groupby(model_col).mean()\n",
    "        plt.figure(figsize=(8,5))\n",
    "        for m in DESIRED_ORDER:\n",
    "            if m in avg_det.index:\n",
    "                plt.plot(thresholds_det, avg_det.loc[m].values, marker='o', label=m)\n",
    "        plt.xlabel(\"IoU threshold (%)\"); plt.ylabel(\"DetA\"); plt.title(\"DetA vs IoU - Average\")\n",
    "        plt.legend(); plt.tight_layout()\n",
    "        p = os.path.join(OUT_DIR, f\"deta_vs_iou_Average.pdf\"); plt.savefig(p); plt.close(); print(\"Saved:\", p)\n",
    "\n",
    "# -----------------------\n",
    "# IDSW & Frag por modelo (por seq y Average)\n",
    "# -----------------------\n",
    "for key in list(grouped_by_seq.keys()):\n",
    "    gm = grouped_by_seq.get(key)\n",
    "    if gm is None or gm.empty:\n",
    "        continue\n",
    "    x = np.arange(len(DESIRED_ORDER))\n",
    "    plt.figure(figsize=(10,4))\n",
    "    width = 0.35\n",
    "    idsw_vals = safe_get_vals(gm, 'IDSW', DESIRED_ORDER)\n",
    "    frag_vals = safe_get_vals(gm, 'Frag', DESIRED_ORDER)\n",
    "    plt.bar(x - width/2, idsw_vals, width, label='IDSW')\n",
    "    plt.bar(x + width/2, frag_vals, width, label='Frag')\n",
    "    plt.xticks(x, DESIRED_ORDER, rotation=45, ha='right')\n",
    "    plt.ylabel(\"Valor medio\")\n",
    "    plt.title(f\"IDSW y Frag por modelo - {key}\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    p = os.path.join(OUT_DIR, f\"idsw_frag_por_modelo_{key}.pdf\"); plt.savefig(p); plt.close(); print(\"Saved:\", p)\n",
    "\n",
    "# -----------------------\n",
    "# Matriz / heatmap composite: Tracking1, Tracking2, Average\n",
    "# -----------------------\n",
    "# Primero construimos df_seq_composite (por-seq normalizando métricas dentro de cada seq)\n",
    "def compute_seq_composites_table(df_seq_model_table, model_col, metrics_map):\n",
    "    rows = []\n",
    "    metrics_for_score = [c for c in ['AssA_AUC','IDF1','HOTA_AUC','MT_percent','IDSW','Frag'] if c in df_seq_model_table.columns]\n",
    "    if not metrics_for_score:\n",
    "        return pd.DataFrame()\n",
    "    for seq, g in df_seq_model_table.groupby('seq'):\n",
    "        g2 = g.copy()\n",
    "        # Normalizar por seq\n",
    "        norm_vals = {}\n",
    "        for c in metrics_for_score:\n",
    "            vals = g2[c].astype(float).values.reshape(-1,1)\n",
    "            if np.nanmax(vals) == np.nanmin(vals):\n",
    "                norm_vals[c+'_norm'] = np.full(vals.shape, 0.5).flatten()\n",
    "            else:\n",
    "                norm_vals[c+'_norm'] = MinMaxScaler().fit_transform(vals).flatten()\n",
    "        for i, row in g2.iterrows():\n",
    "            model_name = row[model_col]\n",
    "            row_out = {'seq': seq, model_col: model_name}\n",
    "            for c in metrics_for_score:\n",
    "                row_out[c] = row[c]\n",
    "                row_out[c + '_norm'] = float(norm_vals[c + '_norm'][list(g2.index).index(i)])\n",
    "            rows.append(row_out)\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    # composite raw\n",
    "    weights = {'AssA_AUC_norm':0.35,'IDF1_norm':0.25,'HOTA_AUC_norm':0.15,'MT_percent_norm':0.10,'IDSW_norm':-0.10,'Frag_norm':-0.10}\n",
    "    df_out['composite_score_raw'] = 0.0\n",
    "    for k,w in weights.items():\n",
    "        if k in df_out.columns:\n",
    "            df_out['composite_score_raw'] += w * df_out[k]\n",
    "    # normalize per seq\n",
    "    df_out = df_out.groupby('seq').apply(\n",
    "        lambda g2: g2.assign(composite_score = (g2['composite_score_raw'] - g2['composite_score_raw'].min()) / (g2['composite_score_raw'].max() - g2['composite_score_raw'].min()) if g2['composite_score_raw'].max() > g2['composite_score_raw'].min() else 0.0)\n",
    "    ).reset_index(drop=True)\n",
    "    return df_out\n",
    "\n",
    "# Construir df_seq_model_short (asegurando nombres cortos presentes)\n",
    "df_seq_model_short = df_seq_model.copy() if 'df_seq_model' in locals() else pd.DataFrame()\n",
    "# Si df_seq_model_short usa nombres de columna largos, renombrar a short donde aplique\n",
    "rename_map_long_to_short = {v:k for k,v in metrics_map.items() if v in df_seq_model_short.columns}\n",
    "if rename_map_long_to_short:\n",
    "    df_seq_model_short = df_seq_model_short.rename(columns=rename_map_long_to_short)\n",
    "\n",
    "df_seq_composite = compute_seq_composites_table(df_seq_model_short, model_col, metrics_map)\n",
    "\n",
    "# Pivot para Tracking1 y Tracking2, y agregar Average como fila\n",
    "pivot = df_seq_composite[df_seq_composite['seq'].isin(SEQ_LIST)].pivot(index='seq', columns=model_col, values='composite_score')\n",
    "if not pivot.empty:\n",
    "    avg_row = pivot.mean(axis=0).to_frame().T\n",
    "    avg_row.index = ['Average']\n",
    "    pivot = pd.concat([pivot, avg_row])\n",
    "    cols_present = [c for c in DESIRED_ORDER if c in pivot.columns]\n",
    "    other_cols = [c for c in pivot.columns if c not in cols_present]\n",
    "    pivot = pivot[cols_present + other_cols]\n",
    "else:\n",
    "    pivot = pd.DataFrame(index=SEQ_LIST + ['Average'])  # vacío\n",
    "\n",
    "pivot_path = os.path.join(OUT_DIR, \"seq_model_composite_matrix_tracking12.csv\")\n",
    "pivot.to_csv(pivot_path)\n",
    "print(\"Guardado pivot:\", pivot_path)\n",
    "\n",
    "plt.figure(figsize=(8, 2 + 0.8*len(pivot.index)))\n",
    "plt.imshow(pivot.values, aspect='auto', interpolation='nearest')\n",
    "plt.yticks(range(len(pivot.index)), pivot.index)\n",
    "plt.xticks(range(len(pivot.columns)), pivot.columns, rotation=45, ha='right')\n",
    "plt.colorbar(label='composite_score (0-1)')\n",
    "plt.title(\"Heatmap: composite_score (Tracking1, Tracking2, Average)\")\n",
    "plt.tight_layout()\n",
    "heatmap_path = os.path.join(OUT_DIR, \"seq_model_composite_heatmap_tracking12.pdf\")\n",
    "plt.savefig(heatmap_path); plt.close()\n",
    "print(\"Saved heatmap:\", heatmap_path)\n",
    "\n",
    "# -----------------------\n",
    "# Rankings por seq (CSV)\n",
    "# -----------------------\n",
    "seq_rankings = df_seq_composite[df_seq_composite['seq'].isin(SEQ_LIST)].copy() if not df_seq_composite.empty else pd.DataFrame()\n",
    "if not seq_rankings.empty:\n",
    "    avg_composite = seq_rankings.groupby(model_col)['composite_score_raw'].mean().reset_index()\n",
    "    if avg_composite['composite_score_raw'].max() > avg_composite['composite_score_raw'].min():\n",
    "        avg_composite['composite_score'] = (avg_composite['composite_score_raw'] - avg_composite['composite_score_raw'].min()) / (avg_composite['composite_score_raw'].max() - avg_composite['composite_score_raw'].min())\n",
    "    else:\n",
    "        avg_composite['composite_score'] = 0.0\n",
    "    avg_composite['seq'] = 'Average'\n",
    "    seq_rankings_combined = pd.concat([seq_rankings, avg_composite.rename(columns={model_col:model_col})], sort=False, ignore_index=True, axis=0)\n",
    "    seq_rankings_path = os.path.join(OUT_DIR, \"seq_model_rankings_tracking12.csv\")\n",
    "    seq_rankings_combined.to_csv(seq_rankings_path, index=False)\n",
    "    print(\"Guardado seq rankings:\", seq_rankings_path)\n",
    "else:\n",
    "    print(\"No hay df_seq_composite para guardar rankings.\")\n",
    "\n",
    "print(\"Análisis completado. Resultados en:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memoria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
