{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd9e2e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatos de export detectados: FP16, INT8, Pytorch\n",
      "Se generarán análisis específicos para: Pytorch, FP16, INT8\n",
      "\n",
      "=== Análisis para global ===\n",
      "Filas consideradas: 108\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'detect_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 509\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# REMOVED: análisis por tracker y combinaciones export+tracker\u001b[39;00m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# (Se eliminó bloque que definía tracker_values_detected, target_trackers y bucle de combinaciones)\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label, df_subset, out_dir \u001b[38;5;129;01min\u001b[39;00m analysis_targets:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     run_analysis_for_subset(df_subset, out_dir, label)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 229\u001b[39m, in \u001b[36mrun_analysis_for_subset\u001b[39m\u001b[34m(df_input, out_dir, label, seq_list, desired_order)\u001b[39m\n\u001b[32m    226\u001b[39m df = df_input.copy()\n\u001b[32m    227\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFilas consideradas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m seq_present, seq_labels_for_outputs = detect_sequences(df, seq_list)\n\u001b[32m    230\u001b[39m model_col = detect_model_column(df)\n\u001b[32m    231\u001b[39m metrics_map, detected_raw = detect_metrics(df, METRIC_CANDIDATES)\n",
      "\u001b[31mNameError\u001b[39m: name 'detect_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Análisis de tracking para Tracking1, Tracking2 y Average(Tracking1,Tracking2).\n",
    "- Detecta columnas relevantes del CSV.\n",
    "- Convierte las columnas métricas a numérico (coerce).\n",
    "- Agrupa por modelo y por (seq, model).\n",
    "- Calcula composite_score basado en métricas de asociación/identidad.\n",
    "- Genera CSVs y PDFs con gráficas, forzando orden de modelos:\n",
    "    Salmones2024, yolov8m, yolov8l, yolov9c, yolo11m, yolo11l\n",
    "- Extiende el análisis para ejecutar versiones específicas por formato de exportación (Pytorch, FP16, INT8).\n",
    "\n",
    "Simplificado: se elimina toda la lógica de análisis por tracker y combinaciones export+tracker.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "IN_PATH = \"combined_results.csv\"           # Cambia si tu CSV está en otra ruta\n",
    "BASE_OUT_DIR = \"results\"                   # Carpeta de salida raíz\n",
    "SEQ_LIST = [\"Tracking1\", \"Tracking2\"]      # Secuencias objetivo\n",
    "DESIRED_ORDER = ['Salmones2024', 'yolov8m', 'yolov8l', 'yolov9c', 'yolo11m', 'yolo11l']\n",
    "EXPORT_VARIANTS = [\"Pytorch\", \"FP16\", \"INT8\"]  # Formatos de exportación a analizar individualmente\n",
    "\n",
    "os.makedirs(BASE_OUT_DIR, exist_ok=True)\n",
    "\n",
    "METRIC_CANDIDATES = {\n",
    "    'IDF1'      : ['IDF1','IDF_1','ID_F1'],\n",
    "    'AssA_AUC'  : ['AssA___AUC','AssA_AUC','AssA AUC','AssA'],\n",
    "    'HOTA_AUC'  : ['HOTA___AUC','HOTA_AUC','HOTA'],\n",
    "    'MT'        : ['MT','MTR','Mostly-Tracked','MostlyTracked'],\n",
    "    'PT'        : ['PT','Partially-Tracked','PartiallyTracked'],\n",
    "    'ML'        : ['ML','Mostly-Lost','MostlyLost'],\n",
    "    'IDSW'      : ['IDSW','ID Sw','ID_Switches','id switches'],\n",
    "    'Frag'      : ['Frag','FRAG','Fragmentation','Frags'],\n",
    "    'GT_IDs'    : ['GT_IDs','GT_ID','GT_IDS','GT_IDs','GT_IDs '],\n",
    "    'Dets'      : ['Dets','Detections','GT_Dets','Dets '],\n",
    "    'MT_percent': ['MT_percent','MT(%)','MT %']\n",
    "}\n",
    "\n",
    "METRIC_DISPLAY_ORDER = ['IDF1','AssA_AUC','HOTA_AUC','MT','PT','ML','IDSW','Frag']\n",
    "\n",
    "def detect_model_column(df):\n",
    "    # prefer 'model', luego 'export', luego alguna columna object con >1 valor, si no última\n",
    "    if 'model' in df.columns:\n",
    "        return 'model'\n",
    "    if 'export' in df.columns:\n",
    "        return 'export'\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == object and df[c].nunique() > 1:\n",
    "            return c\n",
    "    return df.columns[-1]\n",
    "\n",
    "def ensure_seq_string(df):\n",
    "    if 'seq' in df.columns:\n",
    "        df = df.copy()\n",
    "        df['seq'] = df['seq'].astype(str)\n",
    "    return df\n",
    "\n",
    "# Aesthetic matplotlib\n",
    "plt.style.use('default')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({\n",
    "    'figure.facecolor': 'white',\n",
    "    'figure.edgecolor': 'white',\n",
    "    'axes.facecolor': 'white',\n",
    "    'axes.edgecolor': 'black',\n",
    "    'axes.labelcolor': 'black',\n",
    "    'xtick.color': 'black',\n",
    "    'ytick.color': 'black',\n",
    "    'text.color': 'black',\n",
    "    'legend.facecolor': 'white',\n",
    "    'legend.edgecolor': 'black',\n",
    "    'savefig.facecolor': 'white',\n",
    "    'savefig.edgecolor': 'white',\n",
    "    'savefig.transparent': False,\n",
    "})\n",
    "\n",
    "# -----------------------\n",
    "# Funciones utilitarias generales\n",
    "# -----------------------\n",
    "\n",
    "def slugify_tag(value):\n",
    "    \"\"\"Normaliza strings para usarlos en nombres de carpetas.\"\"\"\n",
    "    text = str(value).strip()\n",
    "    for ch in (\" \", \"/\", \"\\\\\", \":\", \"*\", \"?\", \"\\\"\", \"<\", \">\", \"|\"):\n",
    "        text = text.replace(ch, \"_\")\n",
    "    while \"__\" in text:\n",
    "        text = text.replace(\"__\", \"_\")\n",
    "    return text or \"unknown\"\n",
    "\n",
    "\n",
    "def choose_col(df, preferred_list):\n",
    "    \"\"\"Elige la columna exacta o la primera que contiene el substring.\"\"\"\n",
    "    for p in preferred_list:\n",
    "        if p in df.columns:\n",
    "            return p\n",
    "    for p in preferred_list:\n",
    "        matches = [c for c in df.columns if p.lower() in c.lower()]\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def agg_map_from_metrics(metrics_map, df):\n",
    "    cols = [v for v in metrics_map.values() if v in df.columns and pd.api.types.is_numeric_dtype(df[v])]\n",
    "    return {col: 'mean' for col in cols}\n",
    "\n",
    "\n",
    "def compute_grouped_model(df_sub, model_col, agg_map, metrics_map):\n",
    "    \"\"\"Agrupa df_sub por modelo, usando agg_map seguro, y renombra a short names.\"\"\"\n",
    "    if df_sub.empty:\n",
    "        return pd.DataFrame()\n",
    "    agg_map_sub = {k: v for k, v in agg_map.items() if k in df_sub.columns}\n",
    "    if not agg_map_sub:\n",
    "        return pd.DataFrame()\n",
    "    grp = df_sub.groupby(model_col).agg(agg_map_sub)\n",
    "    rename_map = {v: k for k, v in metrics_map.items() if v in grp.columns}\n",
    "    grp = grp.rename(columns=rename_map)\n",
    "    return grp\n",
    "\n",
    "\n",
    "def add_composite_score(grouped_model):\n",
    "    \"\"\"Anexa columnas normalizadas y composite_score (0..1).\"\"\"\n",
    "    gm = grouped_model.copy()\n",
    "    if gm.empty:\n",
    "        return gm\n",
    "    gm = gm.fillna(0)\n",
    "    norm_cols = [c for c in ['AssA_AUC', 'IDF1', 'HOTA_AUC', 'MT_percent', 'IDSW', 'Frag'] if c in gm.columns]\n",
    "    if norm_cols:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled = scaler.fit_transform(gm[norm_cols])\n",
    "        scaled_df = pd.DataFrame(scaled, index=gm.index, columns=[c + \"_norm\" for c in norm_cols])\n",
    "        gm = pd.concat([gm, scaled_df], axis=1)\n",
    "    weights = {\n",
    "        'AssA_AUC_norm': 0.35,\n",
    "        'IDF1_norm': 0.25,\n",
    "        'HOTA_AUC_norm': 0.15,\n",
    "        'MT_percent_norm': 0.10,\n",
    "        'IDSW_norm': -0.10,\n",
    "        'Frag_norm': -0.10\n",
    "    }\n",
    "    used_weights = {k: w for k, w in weights.items() if k in gm.columns}\n",
    "    score = np.zeros(len(gm))\n",
    "    for k, w in used_weights.items():\n",
    "        score += w * gm[k].values\n",
    "    if score.max() > score.min():\n",
    "        score_norm = (score - score.min()) / (score.max() - score.min())\n",
    "    else:\n",
    "        score_norm = np.zeros_like(score)\n",
    "    gm['composite_score_raw'] = score\n",
    "    gm['composite_score'] = score_norm\n",
    "    return gm\n",
    "\n",
    "\n",
    "def reorder_df_index(df_in, order):\n",
    "    if df_in.empty:\n",
    "        return df_in\n",
    "    present = [m for m in order if m in df_in.index]\n",
    "    others = [m for m in df_in.index if m not in present]\n",
    "    return df_in.reindex(present + others)\n",
    "\n",
    "\n",
    "def safe_get_vals(df_g, metric, model_order):\n",
    "    vals = []\n",
    "    for m in model_order:\n",
    "        if m in df_g.index and metric in df_g.columns:\n",
    "            vals.append(df_g.loc[m, metric])\n",
    "        else:\n",
    "            vals.append(np.nan)\n",
    "    return vals\n",
    "\n",
    "\n",
    "def compute_seq_composites_table(df_seq_model_table, model_col, metrics_map):\n",
    "    rows = []\n",
    "    metrics_for_score = [c for c in ['AssA_AUC', 'IDF1', 'HOTA_AUC', 'MT_percent', 'IDSW', 'Frag'] if c in df_seq_model_table.columns]\n",
    "    if not metrics_for_score or 'seq' not in df_seq_model_table.columns:\n",
    "        return pd.DataFrame()\n",
    "    for seq, g in df_seq_model_table.groupby('seq'):\n",
    "        g2 = g.copy()\n",
    "        norm_vals = {}\n",
    "        for c in metrics_for_score:\n",
    "            vals = g2[c].astype(float).values.reshape(-1, 1)\n",
    "            if np.isnan(vals).all() or np.nanmax(vals) == np.nanmin(vals):\n",
    "                norm_vals[c + '_norm'] = np.full(vals.shape, 0.5).flatten()\n",
    "            else:\n",
    "                norm_vals[c + '_norm'] = MinMaxScaler().fit_transform(vals).flatten()\n",
    "        for idx, row in g2.iterrows():\n",
    "            model_name = row[model_col]\n",
    "            row_out = {'seq': seq, model_col: model_name}\n",
    "            for c in metrics_for_score:\n",
    "                row_out[c] = row[c]\n",
    "                row_out[c + '_norm'] = float(norm_vals[c + '_norm'][list(g2.index).index(idx)])\n",
    "            rows.append(row_out)\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    weights = {'AssA_AUC_norm': 0.35, 'IDF1_norm': 0.25, 'HOTA_AUC_norm': 0.15, 'MT_percent_norm': 0.10, 'IDSW_norm': -0.10, 'Frag_norm': -0.10}\n",
    "    df_out['composite_score_raw'] = 0.0\n",
    "    for k, w in weights.items():\n",
    "        if k in df_out.columns:\n",
    "            df_out['composite_score_raw'] += w * df_out[k]\n",
    "    df_out = df_out.groupby('seq').apply(\n",
    "        lambda g2: g2.assign(\n",
    "            composite_score=(g2['composite_score_raw'] - g2['composite_score_raw'].min()) /\n",
    "            (g2['composite_score_raw'].max() - g2['composite_score_raw'].min())\n",
    "            if g2['composite_score_raw'].max() > g2['composite_score_raw'].min() else 0.0\n",
    "        )\n",
    "    ).reset_index(drop=True)\n",
    "    return df_out\n",
    "\n",
    "# -----------------------\n",
    "# Núcleo del análisis parametrizable por subconjunto\n",
    "# -----------------------\n",
    "\n",
    "def run_analysis_for_subset(df_input, out_dir, label, seq_list=SEQ_LIST, desired_order=DESIRED_ORDER):\n",
    "    print(f\"\\n=== Análisis para {label} ===\")\n",
    "    if df_input is None or df_input.empty:\n",
    "        print(\"Sin datos para analizar. Se omite.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    df = df_input.copy()\n",
    "    print(f\"Filas consideradas: {len(df)}\")\n",
    "\n",
    "    seq_present, seq_labels_for_outputs = detect_sequences(df, seq_list)\n",
    "    model_col = detect_model_column(df)\n",
    "    metrics_map, detected_raw = detect_metrics(df, METRIC_CANDIDATES)\n",
    "    df = ensure_numeric_metrics(df, metrics_map)\n",
    "    df, metrics_map = ensure_mt_percent(df, metrics_map)\n",
    "    detected_raw['MT_percent'] = metrics_map.get('MT_percent')\n",
    "    print(\"Columnas detectadas:\")\n",
    "    print(\" model_col:\", model_col)\n",
    "    for key in METRIC_DISPLAY_ORDER + ['MT_percent']:\n",
    "        print(f\" {key}:\", detected_raw.get(key))\n",
    "    print(\"Métricas mapeadas:\")\n",
    "    for k, v in metrics_map.items():\n",
    "        print(\" -\", k, \"->\", v)\n",
    "    agg_map = agg_map_from_metrics(metrics_map, df)\n",
    "    print(\"Agg map (columnas numéricas que se usarán para mean):\")\n",
    "    print(agg_map)\n",
    "\n",
    "    grouped_by_seq, df_seq_model, seq_for_agg = build_grouped_views(\n",
    "        df, seq_labels_for_outputs, seq_present, model_col, agg_map, metrics_map, desired_order\n",
    "    )\n",
    "\n",
    "    # Guardar CSV resumen por modelo para cada vista\n",
    "    for key, gm in grouped_by_seq.items():\n",
    "        if gm is None or gm.empty:\n",
    "            continue\n",
    "        out_path = os.path.join(out_dir, f\"model_summary_{key}.csv\")\n",
    "        gm.sort_values('composite_score', ascending=False).to_csv(out_path)\n",
    "        print(\"Guardado:\", out_path)\n",
    "\n",
    "    # Plots: métricas clave por modelo\n",
    "    plot_metrics = [\n",
    "        c for c in ['IDF1', 'AssA_AUC', 'HOTA_AUC', 'MT_percent']\n",
    "        if any(c in grouped_by_seq[k].columns for k in grouped_by_seq)\n",
    "    ]\n",
    "    for key in list(grouped_by_seq.keys()):\n",
    "        gm = grouped_by_seq[key]\n",
    "        if gm is None or gm.empty:\n",
    "            continue\n",
    "        x = np.arange(len(desired_order))\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        width = 0.15\n",
    "        n = len(plot_metrics)\n",
    "        for i, metric in enumerate(plot_metrics):\n",
    "            vals = safe_get_vals(gm, metric, desired_order)\n",
    "            plt.bar(x + (i - (n - 1) / 2) * width, vals, width, label=metric)\n",
    "        plt.xticks(x, desired_order, rotation=45, ha='right')\n",
    "        plt.ylabel(\"Valor medio (por seq)\")\n",
    "        plt.title(f\"Comparación métricas clave por modelo - {key}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        p = os.path.join(out_dir, f\"metricas_clave_por_modelo_{key}.pdf\")\n",
    "        plt.savefig(p)\n",
    "        plt.close()\n",
    "        print(\"Plot guardado:\", p)\n",
    "\n",
    "    # Curvas AssA & DetA por IoU (por seq y Average)\n",
    "    ass_cols = [c for c in df.columns if c.startswith(\"AssA___\") and c.split(\"___\")[-1].isdigit()]\n",
    "    det_cols = [c for c in df.columns if c.startswith(\"DetA___\") and c.split(\"___\")[-1].isdigit()]\n",
    "\n",
    "    thresholds_ass = [int(c.split(\"___\")[-1]) for c in ass_cols] if ass_cols else []\n",
    "    thresholds_det = [int(c.split(\"___\")[-1]) for c in det_cols] if det_cols else []\n",
    "\n",
    "    if 'seq' in df.columns and seq_labels_for_outputs:\n",
    "        for seq_name in seq_labels_for_outputs:\n",
    "            df_sub = df[df['seq'] == seq_name]\n",
    "            if df_sub.empty:\n",
    "                continue\n",
    "            if ass_cols:\n",
    "                mean_by_model_ass = df_sub.groupby(model_col)[ass_cols].mean()\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                for m in desired_order:\n",
    "                    if m in mean_by_model_ass.index:\n",
    "                        plt.plot(thresholds_ass, mean_by_model_ass.loc[m].values, marker='o', label=m)\n",
    "                plt.xlabel(\"IoU threshold (%)\")\n",
    "                plt.ylabel(\"AssA\")\n",
    "                plt.title(f\"AssA vs IoU - {seq_name}\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                p = os.path.join(out_dir, f\"assa_vs_iou_{seq_name}.pdf\")\n",
    "                plt.savefig(p)\n",
    "                plt.close()\n",
    "                print(\"Saved:\", p)\n",
    "            if det_cols:\n",
    "                mean_by_model_det = df_sub.groupby(model_col)[det_cols].mean()\n",
    "                plt.figure(figsize=(8, 5))\n",
    "                for m in desired_order:\n",
    "                    if m in mean_by_model_det.index:\n",
    "                        plt.plot(thresholds_det, mean_by_model_det.loc[m].values, marker='o', label=m)\n",
    "                plt.xlabel(\"IoU threshold (%)\")\n",
    "                plt.ylabel(\"DetA\")\n",
    "                plt.title(f\"DetA vs IoU - {seq_name}\")\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                p = os.path.join(out_dir, f\"deta_vs_iou_{seq_name}.pdf\")\n",
    "                plt.savefig(p)\n",
    "                plt.close()\n",
    "                print(\"Saved:\", p)\n",
    "\n",
    "        if ass_cols and seq_for_agg:\n",
    "            mean_seq_model_ass = df[df['seq'].isin(seq_for_agg)].groupby(['seq', model_col])[ass_cols].mean()\n",
    "        else:\n",
    "            mean_seq_model_ass = None\n",
    "        if det_cols and seq_for_agg:\n",
    "            mean_seq_model_det = df[df['seq'].isin(seq_for_agg)].groupby(['seq', model_col])[det_cols].mean()\n",
    "        else:\n",
    "            mean_seq_model_det = None\n",
    "\n",
    "        if ass_cols and mean_seq_model_ass is not None and not mean_seq_model_ass.empty:\n",
    "            avg_ass = mean_seq_model_ass.groupby(model_col).mean()\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            for m in desired_order:\n",
    "                if m in avg_ass.index:\n",
    "                    plt.plot(thresholds_ass, avg_ass.loc[m].values, marker='o', label=m)\n",
    "            plt.xlabel(\"IoU threshold (%)\")\n",
    "            plt.ylabel(\"AssA\")\n",
    "            plt.title(\"AssA vs IoU - Average\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            p = os.path.join(out_dir, f\"assa_vs_iou_Average.pdf\")\n",
    "            plt.savefig(p)\n",
    "            plt.close()\n",
    "            print(\"Saved:\", p)\n",
    "        if det_cols and mean_seq_model_det is not None and not mean_seq_model_det.empty:\n",
    "            avg_det = mean_seq_model_det.groupby(model_col).mean()\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            for m in desired_order:\n",
    "                if m in avg_det.index:\n",
    "                    plt.plot(thresholds_det, avg_det.loc[m].values, marker='o', label=m)\n",
    "            plt.xlabel(\"IoU threshold (%)\")\n",
    "            plt.ylabel(\"DetA\")\n",
    "            plt.title(\"DetA vs IoU - Average\")\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            p = os.path.join(out_dir, f\"deta_vs_iou_Average.pdf\")\n",
    "            plt.savefig(p)\n",
    "            plt.close()\n",
    "            print(\"Saved:\", p)\n",
    "\n",
    "    # IDSW & Frag por modelo (por seq y Average)\n",
    "    for key in list(grouped_by_seq.keys()):\n",
    "        gm = grouped_by_seq.get(key)\n",
    "        if gm is None or gm.empty:\n",
    "            continue\n",
    "        x = np.arange(len(desired_order))\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        width = 0.35\n",
    "        idsw_vals = safe_get_vals(gm, 'IDSW', desired_order)\n",
    "        frag_vals = safe_get_vals(gm, 'Frag', desired_order)\n",
    "        plt.bar(x - width / 2, idsw_vals, width, label='IDSW')\n",
    "        plt.bar(x + width / 2, frag_vals, width, label='Frag')\n",
    "        plt.xticks(x, desired_order, rotation=45, ha='right')\n",
    "        plt.ylabel(\"Valor medio\")\n",
    "        plt.title(f\"IDSW y Frag por modelo - {key}\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        p = os.path.join(out_dir, f\"idsw_frag_por_modelo_{key}.pdf\")\n",
    "        plt.savefig(p)\n",
    "        plt.close()\n",
    "        print(\"Saved:\", p)\n",
    "\n",
    "    # Matriz / heatmap composite: Tracking1, Tracking2, Average\n",
    "    df_seq_model_short = df_seq_model.copy()\n",
    "    rename_map_long_to_short = {v: k for k, v in metrics_map.items() if v in df_seq_model_short.columns}\n",
    "    if rename_map_long_to_short:\n",
    "        df_seq_model_short = df_seq_model_short.rename(columns=rename_map_long_to_short)\n",
    "\n",
    "    if 'seq' in df_seq_model_short.columns and not df_seq_model_short.empty:\n",
    "        df_seq_composite = compute_seq_composites_table(df_seq_model_short, model_col, metrics_map)\n",
    "    else:\n",
    "        df_seq_composite = pd.DataFrame()\n",
    "\n",
    "    seq_for_matrix = seq_for_agg\n",
    "    if not df_seq_composite.empty and seq_for_matrix:\n",
    "        pivot = df_seq_composite[df_seq_composite['seq'].isin(seq_for_matrix)].pivot(index='seq', columns=model_col, values='composite_score')\n",
    "    else:\n",
    "        fallback_index = seq_for_matrix + ['Average'] if seq_for_matrix else ['Average']\n",
    "        pivot = pd.DataFrame(index=fallback_index)\n",
    "\n",
    "    if not pivot.empty:\n",
    "        avg_row = pivot.mean(axis=0).to_frame().T\n",
    "        avg_row.index = ['Average']\n",
    "        pivot = pd.concat([pivot, avg_row])\n",
    "        cols_present = [c for c in desired_order if c in pivot.columns]\n",
    "        other_cols = [c for c in pivot.columns if c not in cols_present]\n",
    "        pivot = pivot[cols_present + other_cols]\n",
    "    pivot_path = os.path.join(out_dir, \"seq_model_composite_matrix_tracking12.csv\")\n",
    "    pivot.to_csv(pivot_path)\n",
    "    print(\"Guardado pivot:\", pivot_path)\n",
    "\n",
    "    if not pivot.empty:\n",
    "        plt.figure(figsize=(8, 2 + 0.8 * len(pivot.index)))\n",
    "        plt.imshow(pivot.values, aspect='auto', interpolation='nearest')\n",
    "        plt.yticks(range(len(pivot.index)), pivot.index)\n",
    "        plt.xticks(range(len(pivot.columns)), pivot.columns, rotation=45, ha='right')\n",
    "        plt.colorbar(label='composite_score (0-1)')\n",
    "        plt.title(\"Heatmap: composite_score (Tracking1, Tracking2, Average)\")\n",
    "        plt.tight_layout()\n",
    "        heatmap_path = os.path.join(out_dir, \"seq_model_composite_heatmap_tracking12.pdf\")\n",
    "        plt.savefig(heatmap_path)\n",
    "        plt.close()\n",
    "        print(\"Saved heatmap:\", heatmap_path)\n",
    "    else:\n",
    "        print(\"No se pudo generar heatmap para\", label)\n",
    "\n",
    "    if not df_seq_composite.empty and seq_for_matrix:\n",
    "        seq_rankings = df_seq_composite[df_seq_composite['seq'].isin(seq_for_matrix)].copy()\n",
    "    else:\n",
    "        seq_rankings = pd.DataFrame()\n",
    "    if not seq_rankings.empty:\n",
    "        avg_composite = seq_rankings.groupby(model_col)['composite_score_raw'].mean().reset_index()\n",
    "        if avg_composite['composite_score_raw'].max() > avg_composite['composite_score_raw'].min():\n",
    "            avg_composite['composite_score'] = (\n",
    "                (avg_composite['composite_score_raw'] - avg_composite['composite_score_raw'].min()) /\n",
    "                (avg_composite['composite_score_raw'].max() - avg_composite['composite_score_raw'].min())\n",
    "            )\n",
    "        else:\n",
    "            avg_composite['composite_score'] = 0.0\n",
    "        avg_composite['seq'] = 'Average'\n",
    "        seq_rankings_combined = pd.concat([\n",
    "            seq_rankings,\n",
    "            avg_composite.rename(columns={model_col: model_col})\n",
    "        ], sort=False, ignore_index=True, axis=0)\n",
    "        seq_rankings_path = os.path.join(out_dir, \"seq_model_rankings_tracking12.csv\")\n",
    "        seq_rankings_combined.to_csv(seq_rankings_path, index=False)\n",
    "        print(\"Guardado seq rankings:\", seq_rankings_path)\n",
    "    else:\n",
    "        print(\"No hay df_seq_composite para guardar rankings.\")\n",
    "\n",
    "    print(f\"Análisis completado para {label}. Resultados en: {out_dir}\")\n",
    "\n",
    "# -----------------------\n",
    "# Lectura de datos y ejecución por subconjuntos (global + export)\n",
    "# -----------------------\n",
    "\n",
    "df_all = pd.read_csv(IN_PATH)\n",
    "\n",
    "analysis_targets = [(\"global\", df_all, BASE_OUT_DIR)]\n",
    "registered_labels = {\"global\"}\n",
    "\n",
    "def add_subset(label, subset_df):\n",
    "    if subset_df is None or subset_df.empty:\n",
    "        print(f\"Aviso: subset '{label}' sin datos. Se omite.\")\n",
    "        return\n",
    "    if label in registered_labels:\n",
    "        return\n",
    "    out_dir = os.path.join(BASE_OUT_DIR, label)\n",
    "    analysis_targets.append((label, subset_df, out_dir))\n",
    "    registered_labels.add(label)\n",
    "\n",
    "export_values_detected = []\n",
    "target_exports = []\n",
    "if 'export' in df_all.columns:\n",
    "    export_values_detected = sorted(\n",
    "        [v for v in df_all['export'].dropna().unique() if str(v).strip()],\n",
    "        key=lambda v: str(v)\n",
    "    )\n",
    "    if export_values_detected:\n",
    "        print(\"Formatos de export detectados:\", \", \".join(str(v) for v in export_values_detected))\n",
    "    else:\n",
    "        print(\"No se encontraron valores en la columna 'export'.\")\n",
    "    target_exports = [val for val in EXPORT_VARIANTS if val in export_values_detected]\n",
    "    missing_exports = [val for val in EXPORT_VARIANTS if val not in export_values_detected]\n",
    "    if target_exports:\n",
    "        print(\"Se generarán análisis específicos para:\", \", \".join(str(v) for v in target_exports))\n",
    "    else:\n",
    "        print(\"No se encontraron variantes de export objetivo en los datos.\")\n",
    "    if missing_exports:\n",
    "        print(\"Nota: sin datos para:\", \", \".join(str(v) for v in missing_exports))\n",
    "    additional_exports = [val for val in export_values_detected if val not in EXPORT_VARIANTS]\n",
    "    if additional_exports:\n",
    "        print(\"Exportaciones adicionales detectadas:\", \", \".join(str(v) for v in additional_exports))\n",
    "    for val in target_exports:\n",
    "        subset = df_all[df_all['export'] == val]\n",
    "        add_subset(f\"export_{slugify_tag(val)}\", subset)\n",
    "else:\n",
    "    print(\"Aviso: columna 'export' no encontrada. Sólo se generará el análisis global.\")\n",
    "\n",
    "# REMOVED: análisis por tracker y combinaciones export+tracker\n",
    "# (Se eliminó bloque que definía tracker_values_detected, target_trackers y bucle de combinaciones)\n",
    "for label, df_subset, out_dir in analysis_targets:\n",
    "    run_analysis_for_subset(df_subset, out_dir, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memoria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
